{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NEON Workshop","text":"<p>This page uses a custom template and will display the workshop landing page.</p>"},{"location":"neon-aop-gee/","title":"NEON Airborne Remote Sensing in GEE Tutorials","text":"<p>Open Science Initiative</p> <p>Welcome to the NEON Airborne Remote Sensing in Google Earth Engine Resources workshop! This community-driven resource provides comprehensive tutorials for working with AOP raster data products in Google Earth Engine.</p>"},{"location":"neon-aop-gee/#about-this-repository","title":"About This Repository","text":"<p>This repository offers hands-on tutorials to help researchers, students, and practitioners work with NEON Airborne Observation Platform (AOP) data products in Google Earth Engine. Our tutorials cover data generated from three primary sensors:</p> <ul> <li> <p> Hyperspectral Imaging</p> <p>High-resolution spectral data for vegetation analysis and species classification</p> <p>426 spectral bands | 1m spatial resolution</p> </li> <li> <p> LiDAR Sensors</p> <p>3D structural data for canopy height and biomass estimation</p> <p>Point clouds | Derived products</p> </li> <li> <p> RGB Camera</p> <p>High-resolution imagery for visual context and ground truthing</p> <p>10cm spatial resolution | True color</p> </li> </ul>"},{"location":"neon-aop-gee/#repository-status","title":"Repository Status","text":"<p>Active Development</p> <p>This repository is publicly available in the interest of open science but remains under active development.</p> <ul> <li> Check the changelog for recent updates</li> <li> Community contributions are welcome</li> <li> Report issues via GitHub Issues</li> </ul>"},{"location":"neon-aop-gee/#open-science-commitment","title":"Open Science Commitment","text":"<p>We believe in making scientific tools and knowledge accessible to all. This repository reflects our commitment to:</p> <ul> <li>Transparency in data processing workflows</li> <li>Reproducible research methodologies</li> <li>Community-driven development and improvement</li> <li>Educational resources for all skill levels</li> </ul>"},{"location":"neon-aop-gee/#contact-support","title":"Contact &amp; Support","text":""},{"location":"neon-aop-gee/#neon-airborne-observation-platform","title":"NEON Airborne Observation Platform","text":"<p>Primary Contact</p> <p>Organization: National Ecological Observatory Network Airborne Observation Platform (NEON AOP)\u00b9</p> <p> Website: neonscience.org</p> <p>Contact Options:</p> <p> General Contact Form</p> <p> AOP GEE List</p>"},{"location":"neon-aop-gee/#spatial-bytes","title":"Spatial Bytes","text":"<p>Development Partner</p> <p>Website: https://contact.spatialbytes.work/</p> <p>Contact: Information Available Soon</p> <p>Funding Acknowledgment</p> <p>\u00b9 NEON is a project fully funded by the National Science Foundation and operated by Battelle.</p>"},{"location":"old_index/","title":"Working with NEON Airborne Remote Sensing Data in Google Earth Engine","text":"<p>Workshop Overview</p> <p>Learn to harness the power of NEON's airborne remote sensing data through hands-on exercises in Google Earth Engine. This workshop combines ecological insights with cutting-edge cloud computing for regional-scale environmental analysis.</p>"},{"location":"old_index/#about-this-workshop","title":"About This Workshop","text":"<p>The U.S. NSF's National Ecological Observatory Network (NEON) offers extensive ecological data across various temporal and spatial scales. NEON's Airborne Observation Platform (AOP) captures high-resolution hyperspectral imagery, lidar, and RGB photography at 81 U.S. sites, with data spanning 2-10 years. </p> <p>In 2024, 5 AOP datasets were added to the Google Earth Engine publisher catalog, providing another means of accessing and working with NEON data.</p>"},{"location":"old_index/#what-youll-learn","title":"What You'll Learn","text":"Remote Sensing FundamentalsGoogle Earth Engine SkillsMachine Learning Applications <ul> <li>Work with hyperspectral imagery and lidar data</li> <li>Understand spectral signatures and vegetation indices</li> <li>Apply quality assurance best practices</li> </ul> <ul> <li>Set up and navigate the GEE environment</li> <li>Access NEON datasets programmatically</li> <li>Scale analysis from site to regional level</li> </ul> <ul> <li>Integrate ground-based field data</li> <li>Build classification models</li> <li>Generate regional-scale predictions</li> </ul>"},{"location":"old_index/#learning-objectives","title":"Learning Objectives","text":"<ul> <li> Understand NEON AOP data structure and applications</li> <li> Master Google Earth Engine workflows for ecological data</li> <li> Apply quality assurance considerations for remote sensing</li> <li> Integrate field and remote sensing data for machine learning</li> </ul>"},{"location":"old_index/#workshop-schedule","title":"Workshop Schedule","text":"Time  Session  Instructor(s) 11:45 AM Welcome &amp; Introductions Bridget Hass, Kate Murphy, Sam Roy 11:50 AM NEON Airborne Observation Platform Overview Bridget Hass &amp; Kate Murphy 12:05 PM Setting up Google Earth Engine Sam Roy 12:15 PM Lesson 1: Download &amp; Explore Hyperspectral Data Bridget Hass 12:35 PM Lesson 2: Reflectance QA Considerations Bridget Hass 12:55 PM Lesson 3: Hyperspectral Classification Sam Roy 1:05 PM Discussion &amp; Wrap-up All Instructors <p>Duration</p> <p>Total Workshop Time: 1 hour 20 minutes Format: Interactive live-coding sessions</p>"},{"location":"old_index/#prerequisites","title":"Prerequisites","text":"<p>What You Need</p> <ul> <li> Basic familiarity with remote sensing concepts</li> <li> Google account for Earth Engine access</li> <li> Web browser (Chrome recommended)</li> <li> Curiosity about ecological applications!</li> </ul>"},{"location":"old_index/#datasets-featured","title":"Datasets Featured","text":"Dataset Type Resolution Coverage Applications Hyperspectral Imagery 1m spatial, 426 bands All NEON sites Vegetation analysis, species classification LiDAR Point Clouds High-density 3D Structural mapping Canopy height, biomass estimation RGB Photography 10cm spatial Visual context Ground truthing, feature identification"},{"location":"old_index/#meet-your-instructors","title":"Meet Your Instructors","text":"<p>Expert Team</p> <p>Bridget Hass - NEON AOP Specialist Expertise in hyperspectral remote sensing and ecological applications</p> <p>Kate Murphy - NEON AOP Data Scientist Focus on airborne data processing and quality assurance</p> <p>Sam Roy - Google Earth Engine Developer Specializes in cloud-based remote sensing workflows</p>"},{"location":"old_index/#quick-links","title":"Quick Links","text":"<ul> <li> <p> Google Earth Engine</p> <p>Access the cloud computing platform</p> <p> Sign up for GEE</p> </li> <li> <p> NEON Data Portal</p> <p>Explore all NEON datasets</p> <p> Browse Data</p> </li> <li> <p> Workshop Materials</p> <p>Code examples and tutorials</p> <p> GitHub Repository</p> </li> <li> <p> Documentation</p> <p>Detailed guides and references</p> <p> API Documentation</p> </li> </ul>"},{"location":"old_index/#faq","title":"FAQ","text":"Do I need programming experience? <p>Basic familiarity with JavaScript or Python is helpful but not required. We'll provide code examples and walk through each step.</p> What if I don't have a Google Earth Engine account? <p>We'll help you set up access during the workshop. Make sure you have a Google account ready.</p> Can I access the materials after the workshop? <p>Yes! All code examples and datasets will remain available through the NEON Data Portal and GitHub repository.</p> What ecological applications will we cover? <p>Focus areas include vegetation classification, biodiversity monitoring, and ecosystem health assessment using spectral analysis.</p>"},{"location":"old_index/#material-contact-mail-contact-support","title":":material-contact-mail: Contact &amp; Support","text":"<p>Get in Touch</p> <p>NEON Airborne Observation Platform National Science Foundation Project - Operated by Battelle</p> <p> Website: neonscience.org Contact: NEON Contact Form Support: Available throughout the workshop</p> <p>Ready to Start?</p> <p>Join us for an exciting journey into the world of airborne remote sensing and ecological data science! </p>"},{"location":"background/aop_background/","title":"NEON Airborne Observation Platform","text":""},{"location":"background/aop_background/#neon-airborne-observation-platform-aop","title":"NEON Airborne Observation Platform (AOP)","text":"NEON Airborne Remote Sensing"},{"location":"background/aop_background/#aop-payload-sensors","title":"AOP Payload Sensors","text":"<p>The AOP consists of three complete and comparable instrument payloads. Typically, two of the payloads are dedicated to collections of the NEON field sites while the third is dedicated to NEON's Research Support services which support externally driven research. The primary sensors on each payload include:</p> <ol> <li>A discrete and full-waveform lidar to provide three-dimensional structural information of the landscape</li> <li>An imaging spectrometer to allow discrimination of land cover types and chemical content of vegetation</li> <li>A high-resolution digital camera to provide spatially accurate and detailed contextual information</li> <li>A GPS antenna and receiver and Inertial Measurement Unit (IMU) to provide high-accuracy positioning and orientation of the aircraft</li> </ol>"},{"location":"background/aop_background/#aop-data-products","title":"AOP Data Products","text":"<p>The AOP produces approximately 30 data products. The products are separated into categories of Level 1, Level 2, and Level 3 (L1, L2, L3). L1 represents the least processed data products. Additional processing steps are required to transition the L1 data to the derived L2 and L3 data. Broadly, the L1 and L2 products are provided by individual aircraft flight line, while L3 products are provided in 1 km by 1 km tiles. Generally, the data volume for L1 products is the highest and decreases for L2 and L3 products.</p> <p>Data Access</p> <p>Details of the different products within each Level can be found in the individual webpages for each sensor. All AOP data products can be found on the NEON Data Portal, and a subset of the L3 data products are available on Google Earth Engine.</p>"},{"location":"background/aop_background/#imaging-spectrometer-data-products","title":"Imaging Spectrometer Data Products","text":"<p>Level 1 (L1) products include at-sensor radiance and surface reflectance which are distributed by flightline. The image data is georeferenced to the ITRF00 datum and projected into the appropriate UTM zone, and provided at 1 m spatial resolution. Both the radiance and reflectance image data are stored in an HDF5 file format that includes extensive metadata and data quality information. The HDF5 format was selected because of the flexibility it allows in storing associated metadata.</p> <p>Level 2 (L2) products are derived from the L1 surface reflectance and are produced at the same spatial resolution (1 m), datum and map projection as the Level 1 products. The L2 products include a suite of spectral indices designed to strategically combine bands to highlight vegetation characteristics such as photosynthetic activity or water content. For example, NDVI (Normalized Difference Vegetation Index) is a well-known and commonly used vegetation index which combines information from the NIR and Red regions to estimate vegetative greenness and can be used as a proxy for plant health. The L2 products also include fPAR (fraction of photosynthetically active radiation) and LAI (leaf area index), products further derived from vegetation indices. Additionally, a surface Albedo product that estimates the integrated reflectance of all the NIS bands into a single value is also provided. All L2 products are distributed by flightline in a GeoTIFF (gtiff) format. Currently, all vegetation indices, water indices, fPAR, and LAI are delivered with associated simulated error images.</p> <p>Level 3 (L3) products include mosaics of all L1 and L2 products, excluding at-sensor radiance, and are distributed as 1 km x 1 km tiles instead of flightlines. Tiles are created by making a full mosaic of all the data and sub-setting the 1 km x 1 km tiles. The tiles are designed so their boundaries are set to even 1000 m UTM coordinate intervals. During the mosaic generation, the algorithm preferentially selects pixels that were collected under the best weather conditions in regions with multiple potential pixels due to flightline overlap. If weather conditions were equivalent, pixels acquired nearest to nadir of the image acquisition are selected. Generally, this will correspond to pixels that are nearest to the center of the flightline. The tiles are created at the same spatial resolution (1 m) as the L1 and L2 products are in delivered in gtiff format, with the exception of the surface reflectance, which is delivered in HDF5 format.</p>"},{"location":"background/aop_background/#brdf-and-topographic-corrections","title":"BRDF and Topographic Corrections","text":"<p>BRDF Corrections Available</p> <p>Starting in 2024, NEON began producing BRDF (Bidirectional Reflectance Distribution Function) and topographic corrected reflectance data, which include \"bidirectional\" in the name, and end with revision .002 in the Data Product IDs.</p> <p>As of 2025, these bidirectional reflectance are currently only available for data collected between 2022-2024. NEON is beginning to back-process earlier years (pre-2022) to apply the BRDF and topographic corrections. Please look at the data availability charts for each product on the data portal to determine whether the bidirectional data are available. Eventually, only bidirectional data products will be delivered, with the exception of the Level 1 Spectrometer orthorectified surface directional reflectance (DP1.30006.001), which will continue to be delivered, so that researchers who wish to carry out their own BRDF, topographic, or other corrections may do so.</p> <p>The table below shows a full list of NEON's spectrometer-derived data products, including the corresponding bidirectional reflectance data products, if applicable.</p> <p>Table 1: NEON AOP Imaging Spectrometer Datasets</p> Product Name Level Data Product ID (DPID) BRDF-Corrected DPID Spectrometer orthorectified at-sensor radiance L1 DP1.30008.001 - Spectrometer orthorectified surface (bi)directional reflectance L1 DP1.30006.001 DP1.30006.002 Albedo - spectrometer - flightline L2 DP2.30011.001 DP2.30011.002 LAI - spectrometer - flightline L2 DP2.30012.001 DP2.30012.002 fPAR - spectrometer - flightline L2 DP2.30014.001 DP2.30014.002 Canopy water indices - flightline L2 DP2.30019.001 DP2.30019.002 Vegetation indices - spectrometer - flightline L2 DP2.30026.001 DP2.30026.002 Albedo - spectrometer - mosaic L3 DP3.30011.001 DP3.30011.002 LAI - Spectrometer - mosaic L3 DP3.30012.001 DP3.30012.002 fPAR - spectrometer - mosaic L3 DP3.30014.001 DP3.30014.002 Canopy water indices - mosaic L3 DP3.30019.001 DP3.30019.002 Vegetation indices - spectrometer - mosaic L3 DP3.30026.001 DP3.30026.002 <p>In addition to the spectrometer-derived data products, NEON generates 5 lidar-derived products and 2 RGB camera data products, summarized below. These data products provide valuable structural and visual information that compliment the spectrometer data.</p>"},{"location":"background/aop_background/#lidar-data-products","title":"LiDAR Data Products","text":"<p>Table 2: NEON AOP Lidar Datasets</p> Product Name Level Data Product ID (DPID) ATBD Document # LiDAR Slant Range Waveform L1 DP1.30001.001 NEON.DOC.001293 Discrete Return LiDAR Point Cloud L1 DP1.30003.001 NEON.DOC.001292, NEON.DOC.001288 Ecosystem Structure L3 DP3.30015.001 NEON.DOC.002387 Elevation \u2013 LiDAR L3 DP3.30024.001 NEON.DOC.002390 Slope and Aspect \u2013 LiDAR L3 DP3.30025.001 NEON.DOC.003791"},{"location":"background/aop_background/#rgb-camera-products","title":"RGB Camera Products","text":"<p>Table 3: NEON AOP Camera Datasets</p> Product Name Level Data Product ID (DPID) ATBD Document # High-resolution orthorectified camera imagery L1 DP1.30010.001 NEON.DOC.001211vB High-resolution orthorectified camera imagery mosaic L3 DP3.30010.001 NEON.DOC.005052vB"},{"location":"background/aop_background/#summary","title":"Summary","text":"<p>The NEON Airborne Observation Platform represents a cutting-edge approach to continental-scale ecological monitoring, providing researchers with unprecedented access to high-resolution, standardized remote sensing data across diverse ecosystems. The integration of lidar, imaging spectrometry, and high-resolution camera systems creates a comprehensive dataset that enables detailed analysis of ecosystem structure, function, and change over time.</p> <p>The multi-level data processing approach (L1, L2, L3) ensures that researchers can access data at the appropriate level of processing for their specific research needs, from raw sensor measurements to analysis-ready mosaicked products. The recent addition of BRDF and topographic corrections further enhances the scientific value of these datasets by improving comparability across different viewing and illumination conditions.</p> <p>Getting Started</p> <p>To begin working with NEON AOP data, visit the NEON Data Portal to explore available datasets, or check out the Google Earth Engine catalog for cloud-based analysis of L3 products.</p> <p>Additional Resources</p> <p>For detailed technical information about data processing algorithms and product specifications, refer to the ATBD (Algorithm Theoretical Basis Document) numbers listed in the tables above, available through the NEON Data Portal.</p>"},{"location":"background/neon_aop_gee_data/","title":"Introduction to AOP Data in Google Earth Engine (GEE)","text":"<p>AOP has published a subset of AOP Level 3 (mosaicked) data products at 5 NEON sites (as of Spring 2022) on GEE. This data has been converted to Cloud Optimized GeoTIFF (COG) format. NEON L3 lidar and derived spectral indices are available in geotiff raster format, so are relatively straightforward to add to GEE, however the hyperspectral data is available in hdf5 (hierarchical data) format, and have been converted to the COG format prior to being added to GEE.</p> <p>The NEON data products that have been made available on GEE can be accessed through the <code>projects/neon</code> folder with an appended prefix of the Data Product ID, matching the NEON data portal. The table below summarizes the prefixes to use for each data product, and is a useful reference for reading in AOP GEE datasets. You will see how to access and read in these data products in the next part of this lesson.</p> Acronym Data Product Data Product ID (Prefix) SDR Surface Directional Reflectance DP3-30006-001_SDR RGB Red Green Blue (Camera Imagery) DP3-30010-001_RGB DEM Digital Surface and Terrain Models (DSM/DTM) DP3-30024-001_DEM CHM Canopy Height Model DP3-30015-001_CHM <p>The table below summarizes the sites, products, and years of NEON AOP data that can currently be accessed in GEE.</p> Domain Site Years Data Products D08 TALL 2017, 2018 SDR, RGB, CHM, DSM, DTM D11 CLBJ 2017, 2019 SDR, RGB, CHM, DSM, DTM D14 SRER 2017, 2018, 2019, 2021 SDR, RGB, CHM, DSM, DTM D16 WREF 2017, 2018 SDR, RGB, CHM, DSM, DTM D17 TEAK 2017, 2018 SDR, RGB, CHM, DSM, DTM"},{"location":"background/neon_aop_gee_data/#get-started-with-google-earth-engine","title":"Get Started with Google Earth Engine","text":"<p>Once you have set up your Google Earth Engine account you can navigate to the Earth Engine Code Editor. The diagram below, from the Earth-Engine Playground, shows the main components of the code editor. If you have used other programming languages such as R, Python, or Matlab, this should look fairly similar to other Integrated Development Environments (IDEs) you may have worked with. The main difference is that this has an interactive map at the bottom, similar to Google Maps and Google Earth. This editor is fairly intuitive. We encourage you to play around with the interactive map, or explore the ee documentation, linked above, to gain familiarity with the various features.</p>"},{"location":"background/neon_aop_gee_data/#read-aop-data-collections-into-gee","title":"Read AOP Data Collections into GEE","text":"<p>AOP data can be accessed through GEE through the <code>projects/neon</code> folder. In the remainder of this lesson, we will look at the three AOP datasets, or <code>ImageCollection</code>s in this folder.</p> <p>An ImageCollection is simply a group of images. To find publicly available datasets (primarily satellite data), you can explore the Earth Engine Data Catalog. Currently, NEON AOP data cannot be discovered in the main GEE data catalog, so the following steps will walk you through how to find available AOP data.</p> <p>In your code editor, copy and run the following lines of code to create 3 <code>ImageCollection</code> variables containing the Surface Directional Reflectance (SDR), Camera Imagery (RGB) and Digital Surface and Terrain Model (DEM) raster data sets.</p> <pre><code>//read in the AOP image collections as variables\n\nvar aopSDR = ee.ImageCollection('projects/neon/DP3-30006-001_SDR')\n\nvar aopRGB = ee.ImageCollection('projects/neon/DP3-30010-001_RGB')\n\nvar aopDEM = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n</code></pre> <p>A few tips for the Code Editor: - In the left panel of the code editor, there is a Docs tab which includes API documentation on built in functions, showing the expected input arguments. We encourage you to refer to this documentation, as well as the  GEE JavaScript Tutorial to familiarize yourself with GEE and the JavaScript programming language. - If you have an error in your code, a red error message will show up in the Console (in the right panel), which tells you the line that failed. - Save your code frequently! If you try to leave your code while it is unsaved, you will be prompted that there are unsaved changes in the editor.</p> <p>When you Run the code above (by clicking on the Run above the code editor), you will notice that the lines of code become underlined in red, the same as you would see for a spelling error in most text editors. If you hover over each of the lines of codes, you will see a message pop up that says: <code>&lt;variable&gt; can be converted to an import record. Convert Ignore</code>.</p> <p>If you click <code>Convert</code>, the line of code will disappear and the variable will be imported into your session directly, and will show up at the top of the code editor. Go ahead and convert the variables for all three lines of code, so you should see the following. Tip: if you type Ctrl-z, you can re-generate the line of code, and the variable will still show up in the imported variables at the top of the editor. It is a good idea to retain the original code that reads in the variable, for reproducibility. If you don't do this, and wish to share this code with someone else, or run the code outside of your own code editor, the imported variables will not be saved.</p> <p>Note that each of these imported variables can now be expanded, using the arrow to the left of each. These variables now show associated information including type, id, and properties, which if you expand, shows a description. This provides more detailed information about the data product.</p> <p>Information about the image collections can also be found in a slightly more user-friendly format if you click on the blue <code>projects/neon/DP3-30006-001_SDR</code>, as well as <code>DP3-30010-001_RGB</code> and<code>DP3-30024-001_DEM</code>, respectively. Below we'll show the window that pops-up when you click on <code>SDR</code>, but we encourage you to look at all three datasets.</p> <p>This allows you to read the full description in a more user-friendly format. Note that the images imported into GEE may have some slight differences from the data downloaded from the data portal. For example, note that the reflectance data in GEE is scaled by 100. We highly encourage you to explore the description and associated documentation for the data products on the NEON data portal as well (eg. DP3.30006.001) for relevant information about the data products, how they are generated, and other pertinent details.</p> <p>You can also click on the <code>IMAGES</code> tab to explore all the available NEON images for that data product. Some of the text may be cut off in the default view, but if you click in one of the table values the table will expand. This table summarizes individual sites and years that are available for the SDR Image Collection. The ImageID provides the path to read in an individual image. In the next step, we will show how to use this path to pull in a single file.</p>"},{"location":"background/neon_aop_gee_data/#read-aop-data-into-gee-using-eeimage","title":"Read AOP Data into GEE using <code>ee.Image</code>","text":"<p>As a last step, we will go ahead and use the path specified in the SDR Asset Details Images table to read in a single image. Pulling in a single image uses almost identical syntax as an image collection, see below:</p> <pre><code>var TALL_2017_SDR = ee.Image('projects/neon/DP3-30006-001_SDR/DP3-30006-001_D08_TALL_SDR_2017')\n</code></pre> <p>Import this variable, and you can see that it pulls in to the Imports at the top, and shows <code>(426 bands)</code> at the right. To the right of that you will see blue eye and target icons. If you hover over the eye it displays \"Show on Map\". Click this eye icon to place a footprint of this data set in the Map display. If you hover over the target icon, you will see the option \"Center Map on Record\". Click this to center your map on this TALL SDR dataset. You should now see the footprint of the data as a layer in the Google Map.</p>"},{"location":"background/neon_aop_gee_data/#a-quick-recap","title":"A Quick Recap","text":"<p>You did it! You should now have a basic understanding of the GEE code editor and it's different components. You have also learned how to read a NEON AOP <code>ImageCollection</code> into a variable, import the variable into your code editor session, and navigate through the <code>ImageCollection</code> Asset details to find the path to an individual <code>Image</code>. Lastly, you learned to read in an individual SDR Image, pull the footprint of the data into a Map Layer, and center on that region.</p> <p>It doesn't look like we've done much so far, but this is a already great achievement! With just a few lines of code, you can import an entire AOP hyperspectral data set, which in most other coding environments, is not simple. One of the barriers to working with AOP data (and reflectance data in particular) is it's large data volume, which requires high-performance computing environments to carry out analysis. There are also limited open-source tools for working with the data; many of the software suites for working with hyperspectral data require licenses which can be expensive. In this lesson, we have loaded spectral data covering an entire site, and are ready for data exploration and analysis, in a free geospatial cloud-computing platform.</p> <p>In the next tutorials, we will pull in spectral data, visualize RGB and false color image composites, interactively plot spectral signatures of pixels in the image, and carry out some more advanced analysis that is highly simplified by the built in GEE functions.</p>"},{"location":"background/neon_aop_gee_data/#get-lesson-code","title":"Get Lesson Code","text":"<p>Into to AOP GEE Assets \u2192 \u2192</p>"},{"location":"background/neon_background/","title":"What is NEON?","text":"<p>NEON is a continental-scale observation facility designed to collect long-term open-access ecological data to better understand the complexities of Earth's ecosystems and how they are changing. NEON uses cutting-edge sensor networks, instrumentation, observational sampling, natural history archive facilities and remote sensing methods and technologies to collect data on plants, animals, soil, nutrients, freshwater and the atmosphere.</p> <p>NEON operates 81 field sites strategically located across 20 ecoclimatic Domains across the United States, including 47 terrestrial sites and 34 freshwater aquatic sites. When logistically possible, aquatic and terrestrial field sites are colocated (i.e. in close proximity) to support understanding of linkages across terrestrial and aquatic ecosystems and their interactions with the atmosphere. For example, Domain 08, the Ozarks Complex, has three co-located sets of terrestrial and aquatic field sites. These sites are situated along the same watershed system, creating a unique opportunity to study hydrology, nutrient transport, and biogeochemical cycling through the watershed.</p> <p> </p> NEON Field Sites Map - Green: Terrestrial Sites, Blue: Aquatic Sites <p>NEON delivers data products from three main sub-systems called the Airborne Observation Platform (AOP), Terrestrial and Aquatic Observational Systems (TOS/AOS), and the Instrumented Systems (TIS/AIS). The section below provides a brief summary of these sub-systems.</p>"},{"location":"background/neon_background/#neon-airborne-observation-platform-aop","title":"NEON Airborne Observation Platform (AOP)","text":"NEON Airborne Remote Sensing <p>Airborne remote sensing surveys are conducted over NEON field sites during peak greenness and provide quantitative information on land cover and changes to ecological structure and chemistry, including the presence and effects of invasive species. The surveys are supported by the NEON Airborne Observation Platform (AOP), a suite of earth observation instruments installed into a Twin Otter aircraft designed to collect high-resolution remote sensing data at low altitude. AOP was designed to collect regional-scale landscape information at the NEON field sites. The AOP maps areas where NEON's observational and instrumented sampling is occurring and allows relationships to be drawn between NEON's detailed in-situ observations to the broader environmental and ecological conditions.</p> <p>Learn More</p> <p>Please see the next section Airborne Observation Platform for more details on the AOP including a summary of the data products provided.</p>"},{"location":"background/neon_background/#neon-field-data","title":"NEON Field Data","text":"<p>In addition to the AOP remote sensing data, NEON also provides Observational Sampling (OS) data and Instrumented Sampling (IS) data at terrestrial and aquatic sites. The field and instrumented sampling are briefly described below, but we encourage exploring the NEON website further for a more detailed understanding of the sensors and data products provided by the OS and IS groups.</p>"},{"location":"background/neon_background/#observational-sampling","title":"Observational Sampling","text":"NEON Observational Samples <p>NEON field scientists collect a broad variety of observations and samples at terrestrial and aquatic field sites at regular intervals throughout the year. The data and samples collected by NEON's Aquatic Observation System (AOS) and Terrestrial Observation System (TOS) are designed to provide standardized, continentally distributed observations of organisms, biogeochemistry, and physical properties.</p>"},{"location":"background/neon_background/#instrumented-sampling","title":"Instrumented Sampling","text":"NEON Instrumented Sampling <p>NEON deploys automated instruments to collect meteorological, soil, phenological, surface water, and groundwater data at NEON field sites.</p> <p>Colocated Sites</p> <p>Where logistically possible, NEON colocated aquatic sites with terrestrial sites (21 in total) to support an understanding of linkages across atmospheric, terrestrial, and aquatic ecosystems. The suite of OS, IS, and AOP data provide an unparalleled opportunity to study ecosystem-level change over time in the United States.</p>"},{"location":"gee/gee_catalog/","title":"Earth Engine Data Catalog 90+ Petabytes of Geospatial Data","text":"<p>Catalog Overview</p> <p>1000+ datasets \u2022 90+ petabytes of data \u2022 Continuously updated \u2022 Free access to most datasets</p> <p>The Earth Engine data catalog represents one of the world's largest collections of publicly available geospatial datasets. Originally designed around primary datasets curated by the Earth Engine team, the catalog has grown into a comprehensive repository that democratizes access to satellite imagery, climate data, and geophysical datasets from around the globe.</p> <p> </p> Exploring the Earth Engine Data Catalog interface"},{"location":"gee/gee_catalog/#dataset-categories","title":"Dataset Categories","text":"<p>The catalog spans multiple domains of Earth observation and environmental monitoring:</p> Satellite ImageryClimate &amp; WeatherTerrain &amp; TopographyEnvironmental <ul> <li>Landsat Collection - 50+ years of Earth observation</li> <li>Sentinel Series - High-resolution European Space Agency data</li> <li>MODIS - Daily global coverage for environmental monitoring</li> <li>Planet - High-frequency, high-resolution commercial imagery</li> </ul> <ul> <li>ERA5 Reanalysis - Comprehensive atmospheric data</li> <li>CHIRPS - Precipitation datasets for climate monitoring</li> <li>Temperature Records - Historical and real-time temperature data</li> <li>Weather Station Data - Ground-based meteorological observations</li> </ul> <ul> <li>SRTM - Global digital elevation models</li> <li>ASTER GDEM - High-resolution terrain data</li> <li>Global Forest Change - Annual forest loss and gain</li> <li>Land Cover Classifications - Multiple global and regional products</li> </ul> <ul> <li>Air Quality - Pollution and atmospheric composition</li> <li>Ocean Data - Sea surface temperature, salinity, currents</li> <li>Biodiversity - Species distribution and habitat data</li> <li>Urban Development - Built environment and infrastructure</li> </ul>"},{"location":"gee/gee_catalog/#finding-your-data","title":"Finding Your Data","text":""},{"location":"gee/gee_catalog/#quick-search-methods","title":"Quick Search Methods","text":"<p>Search Strategies</p> <p>\ud83d\udd0d By Keywords: Use terms like \"landsat\", \"temperature\", \"precipitation\"</p> <p>\ud83d\uddd3\ufe0f By Date Range: Filter datasets by temporal coverage</p> <p>\ud83c\udf0d By Geographic Area: Search for region-specific datasets</p> <p>\ud83d\udcca By Data Type: Filter by imagery, tables, or image collections</p> <p> </p> Searching for datasets directly in the Earth Engine Code Editor"},{"location":"gee/gee_catalog/#access-points","title":"Access Points","text":"<p>Where to Find Data</p> <p>\ud83c\udf10 Main Catalog Browser - Web-based dataset explorer</p> <p>\ud83d\udccb Complete Dataset List - All available datasets in one view</p> <p>\ud83d\udcbb Code Editor Search - Built-in search within the development environment</p> <p>\ud83d\udcd6 Dataset Tags - Browse by thematic categories</p>"},{"location":"gee/gee_catalog/#specialized-collections","title":"Specialized Collections","text":"<p>Domain-Specific Highlights</p> <p>\ud83c\udf31 Agriculture: Crop type maps, NDVI time series, soil moisture</p> <p>\ud83c\udfd9\ufe0f Urban Planning: Nighttime lights, population density, built-up areas</p> <p>\ud83c\udf0a Water Resources: Surface water occurrence, flood mapping, water quality</p> <p>\ud83d\udd25 Disaster Response: Fire detection, damage assessment, emergency mapping</p>"},{"location":"gee/gee_catalog/#data-licensing-and-usage","title":"Data Licensing and Usage","text":""},{"location":"gee/gee_catalog/#understanding-access-rights","title":"Understanding Access Rights","text":"<p>Important Licensing Information</p> <ul> <li>Most datasets are free for research and non-commercial use</li> <li>Commercial datasets require specific licensing (clearly marked)</li> <li>Citation requirements vary by dataset - check individual dataset pages</li> <li>Usage limits may apply to some high-resolution commercial data</li> </ul>"},{"location":"gee/gee_catalog/#best-practices","title":"Best Practices","text":"Before Using DataFor Reproducible Research <ol> <li>Read the dataset description thoroughly</li> <li>Check temporal and spatial coverage for your area of interest</li> <li>Review licensing terms and citation requirements</li> <li>Understand data quality and known limitations</li> </ol> <ol> <li>Document dataset versions and access dates</li> <li>Include proper citations in publications</li> <li>Note any preprocessing applied to the data</li> <li>Share your analysis code when possible</li> </ol>"},{"location":"gee/gee_catalog/#advanced-catalog-features","title":"Advanced Catalog Features","text":""},{"location":"gee/gee_catalog/#programmatic-access","title":"Programmatic Access","text":"<p>For power users and automated workflows, the catalog can be accessed programmatically:</p> <ul> <li>Earth Engine API - Direct dataset access through code</li> <li>Asset Management - Import and manage your own datasets</li> <li>Shared Assets - Access community-contributed datasets</li> <li>Apps Integration - Use catalog data in Earth Engine Apps</li> </ul>"},{"location":"gee/gee_community_catalog/","title":"Awesome GEE Community Catalog Community-Driven Geospatial Datasets","text":"<p>Community-Powered Data Commons</p> <p>Community-sourced datasets \u2022 Open licenses \u2022 Ready-to-use Earth Engine assets \u2022 Preprocessed for immediate analysis</p> <p>The Awesome GEE Community Catalog represents a grassroots effort to democratize access to geospatial data. This community-driven repository addresses a critical gap: research datasets that often require extensive preprocessing before they can be used in Google Earth Engine. By providing ready-to-use Earth Engine assets, the catalog eliminates barriers and accelerates research workflows.</p> <p> </p> Awesome GEE Community Catalog - Bridging data gaps through community collaboration <p>Project Origins</p> <p>\ud83d\udcd6 Learn More: Community Datasets: Data Commons in Google Earth Engine</p> <p>The project emerged from the recognition that many valuable research datasets remained inaccessible due to preprocessing complexity, licensing confusion, or format incompatibilities.</p>"},{"location":"gee/gee_community_catalog/#why-community-catalog-matters","title":"Why Community Catalog Matters","text":""},{"location":"gee/gee_community_catalog/#addressing-real-challenges","title":"Addressing Real Challenges","text":"Data AccessibilityOpen ScienceResearch Acceleration <ul> <li>Preprocessing Barriers - Complex datasets made analysis-ready</li> <li>Format Standardization - Consistent Earth Engine asset formats</li> <li>Documentation - Clear metadata and usage examples</li> <li>Quality Assurance - Community-validated datasets</li> </ul> <ul> <li>Open Licenses - Transparent usage rights</li> <li>Reproducible Research - Standardized data access</li> <li>Community Validation - Peer-reviewed quality</li> <li>Knowledge Sharing - Collaborative improvement</li> </ul> <ul> <li>Immediate Access - Skip time-consuming preprocessing</li> <li>Tested Examples - Working code for quick starts</li> <li>Domain Organization - Intuitive dataset discovery</li> <li>Regular Updates - Community-maintained freshness</li> </ul>"},{"location":"gee/gee_community_catalog/#dataset-categories","title":"Dataset Categories","text":"<p>The catalog organizes datasets into thematic domains for intuitive discovery:</p>"},{"location":"gee/gee_community_catalog/#core-domains","title":"Core Domains","text":"Domain Focus Areas Example Datasets \ud83c\udfd9\ufe0f Population &amp; Socioeconomics Demographics, economic indicators, urban development Population grids, poverty maps, economic activity \ud83c\udf31 Agriculture &amp; Food Security Crop mapping, yield prediction, food systems Crop type maps, agricultural statistics, food prices \ud83c\udf0a Hydrology &amp; Water Resources Water availability, quality, infrastructure River networks, water bodies, groundwater data \ud83d\udd25 Disasters &amp; Hazards Risk assessment, emergency response Flood maps, fire perimeters, vulnerability indices \ud83c\udf3f Ecology &amp; Biodiversity Species distribution, habitat mapping Protected areas, species occurrence, ecosystem maps \ud83c\udfd7\ufe0f Infrastructure &amp; Transportation Built environment, connectivity Road networks, building footprints, facility locations"},{"location":"gee/gee_community_catalog/#specialized-collections","title":"Specialized Collections","text":"<p>Unique Dataset Highlights</p> <p>\ud83d\udef0\ufe0f Radar &amp; SAR Data - Preprocessed radar datasets for advanced analysis</p> <p>\ud83d\udcca Statistical Surfaces - Gridded statistical data from national surveys</p> <p>\ud83d\uddfa\ufe0f Administrative Boundaries - High-quality boundary datasets for multiple countries</p> <p>\u23f0 Historical Archives - Digitized historical maps and imagery</p>"},{"location":"gee/gee_community_catalog/#navigating-the-catalog","title":"Navigating the Catalog","text":""},{"location":"gee/gee_community_catalog/#discovery-methods","title":"Discovery Methods","text":"Exploring datasets by thematic domains - expand categories to discover relevant datasets <p>Finding the Right Dataset</p> <p>\ud83d\udcc2 Browse by Domain - Expand thematic categories to explore related datasets</p> <p>\ud83d\udd0d Keyword Search - Use the search bar for specific terms, tags, or dataset names</p> <p>\ud83c\udff7\ufe0f Tag Filtering - Combine multiple tags to narrow your search</p> <p>\ud83d\udccb Asset Lists - Each dataset page shows all available Earth Engine assets</p> <p> </p> Using the search functionality to quickly find datasets by name, keywords, or tags"},{"location":"gee/gee_community_catalog/#dataset-pages","title":"Dataset Pages","text":"<p>Each dataset in the catalog provides comprehensive information:</p> Essential InformationTechnical DetailsUsage Resources <ul> <li>Dataset Description - Comprehensive overview and methodology</li> <li>Spatial/Temporal Coverage - Geographic extent and time range</li> <li>Data Source - Original data providers and processing details</li> <li>Licensing Information - Clear usage rights and restrictions</li> </ul> <ul> <li>Earth Engine Asset IDs - Direct links to data assets</li> <li>Coordinate Reference System - Projection and datum information</li> <li>Resolution Specifications - Spatial and temporal resolution</li> <li>Data Quality Notes - Known limitations and considerations</li> </ul> <ul> <li>Example Code - Working JavaScript and Python examples</li> <li>Visualization Parameters - Pre-configured display settings</li> <li>Processing Tips - Best practices for analysis</li> <li>Citation Guidelines - Proper attribution requirements</li> </ul>"},{"location":"gee/gee_community_catalog/#integration-with-earth-engine","title":"Integration with Earth Engine","text":""},{"location":"gee/gee_community_catalog/#code-editor-repository","title":"Code Editor Repository","text":"Adding the community catalog repository to your Earth Engine Code Editor for easy access <p>Easy Integration</p> <p>\ud83d\udd17 Add Repository: Include the entire catalog as a Code Editor repository</p> <p>\ud83d\udcf1 Quick Access: Browse examples directly in your development environment</p> <p>\ud83d\udd04 Automatic Updates: Stay current with new datasets and improved examples</p> <p>\ud83d\udcbb Ready-to-Run Code: Copy and modify examples for your specific needs</p>"},{"location":"gee/gee_community_catalog/#working-with-community-datasets","title":"Working with Community Datasets","text":"<pre><code>// Example: Loading a community dataset\nvar populationGrid = ee.Image('projects/sat-io/open-datasets/worldpop/ppp_2020_1km_Aggregated');\n\n// Apply filtering and visualization\nvar visualization = {\n  min: 0,\n  max: 1000,\n  palette: ['white', 'yellow', 'orange', 'red', 'purple']\n};\n\nMap.addLayer(populationGrid, visualization, 'Population Density 2020');\n</code></pre> <p>Best Practices for Community Data</p> <p>\u26a1 Check Asset Status - Verify asset availability before deployment</p> <p>\ud83d\udcd6 Read Documentation - Understand processing methodology and limitations</p> <p>\ud83c\udff7\ufe0f Use Proper Citations - Credit original data providers and catalog contributors</p> <p>\ud83d\udd04 Stay Updated - Monitor for dataset updates and improvements</p>"},{"location":"gee/gee_community_catalog/#contributing-to-the-catalog","title":"Contributing to the Catalog","text":""},{"location":"gee/gee_community_catalog/#how-to-get-involved","title":"How to Get Involved","text":"<p>Community Participation</p> <p>The catalog thrives on community contributions. Here's how you can help:</p> Data ContributorsTechnical ContributorsCommunity Support <ul> <li>Submit Datasets - Share your preprocessed research datasets</li> <li>Improve Documentation - Enhance existing dataset descriptions</li> <li>Validate Quality - Test and verify dataset accuracy</li> <li>Update Examples - Improve or add new code examples</li> </ul> <ul> <li>Code Development - Enhance catalog infrastructure</li> <li>Bug Reporting - Identify and report issues</li> <li>Feature Requests - Suggest new functionality</li> <li>Testing - Validate new features and datasets</li> </ul> <ul> <li>User Feedback - Share experiences and suggestions</li> <li>Documentation - Improve tutorials and guides</li> <li>Outreach - Promote catalog usage in your networks</li> <li>Training - Help others learn to use community datasets</li> </ul>"},{"location":"gee/gee_community_catalog/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>Quality Standards</p> <p>\ud83d\udccb Documentation Required - Complete metadata and usage examples</p> <p>\u2696\ufe0f Open Licensing - Datasets must use open, clearly specified licenses</p> <p>\ud83d\udd0d Quality Assurance - Data must be validated and tested</p> <p>\ud83e\udd1d Community Review - Submissions undergo peer review process</p>"},{"location":"gee/gee_community_catalog/#impact-and-recognition","title":"Impact and Recognition","text":""},{"location":"gee/gee_community_catalog/#growing-ecosystem","title":"Growing Ecosystem","text":"<p>The Awesome GEE Community Catalog has become an essential resource for the Earth Engine community:</p> <ul> <li>\ud83c\udf0d Global Reach - Used by researchers and practitioners worldwide</li> <li>\ud83d\udcc8 Growing Collection - Continuously expanding dataset portfolio</li> <li>\ud83c\udf93 Educational Value - Supporting teaching and learning initiatives</li> <li>\ud83d\udd2c Research Enablement - Accelerating scientific discoveries</li> </ul>"},{"location":"gee/gee_community_catalog/#academic-citation","title":"Academic Citation","text":"<p>When using datasets from the community catalog, please cite both the original data source and the catalog project:</p> <p>Citation Format</p> <p>Roy, S., &amp; Swetnam, T. (2024). samapriya/awesome-gee-community-datasets: Community Catalog (2.6.0). Zenodo. https://doi.org/10.5281/zenodo.11118613</p>"},{"location":"gee/gee_community_catalog/#getting-started","title":"Getting Started","text":""},{"location":"gee/gee_community_catalog/#quick-start-guide","title":"Quick Start Guide","text":"<ol> <li>\ud83c\udf10 Explore the Catalog - Visit gee-community-catalog.org</li> <li>\ud83d\udd0d Find Your Data - Use search or browse by domain</li> <li>\ud83d\udcd6 Read Documentation - Understand dataset specifications and limitations</li> <li>\ud83d\udcbb Try Examples - Run provided code in Earth Engine Code Editor</li> <li>\ud83d\ude80 Build Your Analysis - Adapt examples for your research needs</li> </ol>"},{"location":"gee/gee_community_catalog/#next-steps","title":"Next Steps","text":"<p>Maximize Your Impact</p> <p>\ud83e\udd1d Join the Community - Engage with other users and contributors</p> <p>\ud83d\udce2 Share Your Work - Showcase analyses built with community datasets</p> <p>\ud83d\udd04 Give Feedback - Help improve datasets and documentation</p> <p>\ud83d\udcda Stay Informed - Follow updates and new dataset announcements</p> <p>The Awesome GEE Community Catalog represents the power of collaborative science - join the community and help democratize access to geospatial data.</p>"},{"location":"gee/gee_overview/","title":"Google Earth Engine Browser Based Remote Sensing","text":"<p>Key Benefits</p> <p>90+ petabytes of open geospatial data \u2022 Cloud-based processing \u2022 JavaScript &amp; Python SDKs \u2022 Scalable analysis from local to global</p> <p>Google Earth Engine brings the power of remote sensing analysis into the browser. With just an internet connection, anyone can tap into this cloud-based platform to process and query massive geospatial datasets.</p> <p>Earth Engine levels the playing field for working with satellite imagery and raster data at scale. It hosts one of the largest repositories of open geospatial assets (over 90+ petabytes), while ingesting new data continuously. Users can perform analysis across these indexed layers, going from local to global, using JavaScript and Python SDKs. The cloud infrastructure allows researchers to iterate rapidly and run computations on petabytes of data. Results are shareable, published outputs that ensure reproducibility. Earth Engine simplifies the process from data access to analysis to dissemination.</p> <p> </p> What is Google Earth Engine <p>Why Earth Engine Matters</p> <p>By moving most of the processing into the cloud, Earth Engine makes remote sensing more accessible. Users now wield these capabilities through any web browser. This democratization of geospatial analytics opens up new possibilities for applications across numerous domains.</p>"},{"location":"gee/gee_overview/#capabilities-and-limitations","title":"Capabilities and Limitations","text":"<p>Understanding what Google Earth Engine excels at\u2014and where it has boundaries\u2014helps you make the most of this powerful platform.</p>"},{"location":"gee/gee_overview/#what-earth-engine-does-best","title":"What Earth Engine Does Best","text":"Image ProcessingVector ProcessingTerrain AnalysisTime SeriesAdvanced Analytics <ul> <li>Map Algebra, Kernels and Convolutions</li> <li>Spectral Unmixing, Pan-sharpening</li> <li>Gap Filling, Data Fusion</li> </ul> <ul> <li>Zonal Statistics, Spatial Joins</li> <li>Spatial Query operations</li> </ul> <ul> <li>Slope, Aspect, Hillshades</li> <li>Hill Shadow Analysis</li> </ul> <ul> <li>Extract Time-Series, Trend Analysis</li> <li>Time-Series Smoothing</li> <li>Temporal Segmentation</li> </ul> <ul> <li>Object-based Image Analysis (GLCM, Texture, Hotspots)</li> <li>Change Detection (Spectral Distance, Change Classification)</li> <li>Machine Learning (Supervised/Unsupervised Classification, PCA)</li> <li>Deep Learning (DNN, Object Detection via TensorFlow)</li> </ul>"},{"location":"gee/gee_overview/#current-limitations","title":"Current Limitations","text":"<p>Not supported in Earth Engine</p> <ul> <li>Cartographic Outputs - No traditional map layout tools</li> <li>3D Visualization - Limited to 2D analysis and display</li> <li>Hydrological Modeling - No rainfall-runoff or watershed tools</li> <li>Photogrammetry - No orthorectification or point cloud processing</li> <li>LiDAR Processing - No specialized LiDAR analysis tools</li> <li>SAR Interferometry - Limited SAR analysis capabilities</li> </ul>"},{"location":"gee/gee_overview/#additional-resources","title":"Additional Resources","text":"<p>Learn More</p> <p>\ud83d\udcc4 Research Paper: Google Earth Engine: Planetary-scale geospatial analysis for everyone</p> <p>\ud83d\udcda Comprehensive Guide: Cloud-Based Remote Sensing with Google Earth Engine: Fundamentals and Applications - Open source book by the GEE community</p> <p> </p> Snippet from the Google Earth Engine main paper. Source"},{"location":"setup/getting_started/","title":"Getting Started","text":"<p>This guide will help you prepare for the workshop by setting up your Google Earth Engine account and understanding the prerequisites.</p>"},{"location":"setup/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Participants should have basic familiarity with Google Earth Engine and experience coding in a scientific language (e.g., Python, R, JavaScript) is recommended. Participants must sign up for a Google Earth Engine account and set up a cloud project to follow along with the live-coding exercises.</p>"},{"location":"setup/getting_started/#setup-instructions","title":"Setup Instructions","text":"<p>To follow along during the workshop, or to run through the tutorials contained within the repository using the Google Earth Engine Code Editor, the following steps are required.</p>"},{"location":"setup/getting_started/#1-google-earth-engine-account","title":"1. Google Earth Engine Account","text":"<p>Create a Noncommercial Google Earth Engine account (if you don't already have one) at https://earthengine.google.com/noncommercial/</p>"},{"location":"setup/getting_started/#2-google-earth-engine-project","title":"2. Google Earth Engine Project","text":"<p>Once your EE account is set up, you will need to create a Google Cloud project. This is required to run the live-coding exercises. You can follow the instructions in the Google Earth Engine access guide to set up your project.</p>"},{"location":"setup/getting_started/#3-hardware-requirements","title":"3. Hardware Requirements","text":"<p>Following along with the exercises requires a laptop or tablet with a stable internet connection.</p>"},{"location":"setup/getting_started/#next-steps","title":"Next Steps","text":"<p>Once you've completed the setup above, you'll be ready to participate in the workshop exercises. Make sure to test your Google Earth Engine access by logging into the Earth Engine Code Editor before the workshop begins.</p> <p>If you encounter any issues during setup, please reach out to the workshop organizers for assistance.</p>"},{"location":"tutorials/aop-sdr-viz-functions/","title":"Function for Visualizing AOP Image Collections in GEE","text":""},{"location":"tutorials/aop-sdr-viz-functions/#writing-a-function-to-visualize-aop-sdr-image-collections","title":"Writing a Function to Visualize AOP SDR Image Collections","text":"<p>In the previous Introduction to AOP Hyperspectral Data in GEE tutorial, we showed how to read in SDR data for images from 3 years. In this tutorial, we will show you a different, more simplified way of doing the same thing, using functions. This is called \"refactoring\". In any coding language, if you notice you are writing very similar lines of code repeatedly, it may be an opportunity to create a function. For example, in the previous tutorial, we repeated lines of code to pull in different years of data at SRER, the only difference being the year and the variable names for each year. As you become more proficient with GEE coding, it is good practice to start writing functions to make your scripts more readable and reproducible.</p> <p>Let's get started! First let's take a look at the syntax for writing user-defined functions in GEE. If you are familiar with other programming languages, this should look somewhat familiar. The function requires input arguments <code>args</code> and returns an <code>output</code>.</p> <pre><code>var myFunction = function(args) {\n  // do something with input args\n  return output;\n};\n</code></pre> <p>To call the function for a full image collection, you can use a  map  to iterate over items in a collection. This is shown in the script below.</p> <pre><code>// Map the function over the collection.\nvar newVariable = collection.map(myFunction);\n</code></pre> <p>For this example, we will provide the full script below, including the function <code>addNISImage</code>, with comments explaining what each part of the function does. Note that a helpful troubleshooting technique is to add in <code>print</code> statements if you are unsure what the code is returning. We have included some print statements in this function below, and show the outputs (which would show up in the console tab). Note that these print statements are commented out in the code linked with this tutorial, since they are not required for the function to run.</p> <pre><code>// Specify center location of SRER\nvar mySite = ee.Geometry.Point([-110.83549, 31.91068])\n\n// Read in the SDR Image Collection\nvar NISimages = ee.ImageCollection('projects/neon/DP3-30006-001_SDR').filterBounds(mySite)\n\n// Create a function to display each NIS Image in the NEON AOP Image Collection\nfunction addNISImage(image) {\n// get the system:id and convert to string\n  var imageId = ee.Image(image.id);\n  // get the system:id - this is an object on the server\n  var sysID_serverObj = ee.String(imageId.get(\"system:id\"));\n  // getInfo() converts to string on the server\n  var sysID_serverStr = sysID_serverObj.getInfo()\n  print(\"systemID: \"+sysID_serverStr)\n  // truncate the string to show only the fileName (NEON domain + site code + product code + year)\n  var fileName = sysID_serverStr.slice(46,100);\n  print(\"fileName: \"+fileName)\n  // mask out no-data values and set visualization parameters to show RGB composite\n  var imageRGB = imageId.updateMask(imageId.gte(0.0000)).select(['band053', 'band035', 'band019']);\n  // add this layer to the map\n  Map.addLayer(imageRGB, {min:2, max:20}, fileName)\n}\n\n// call the addNISimages function\nNISimages.evaluate(function(NISimages) {\n  NISimages.features.map(addNISImage);\n})\n\n// Center the map on SRER\nMap.setCenter(-110.83549, 31.91068, 11);\n</code></pre> <p>Note that the first half of this function is just pulling out relevant information about the site - in order to properly label the layer on the Map display. You should recognize some of the same syntax from the previous tutorial in the last two lines of code in the function, defining the variable <code>imageRGB</code>, using <code>updateMask</code>, and finally using <code>Map.addLayer</code> to add the layer to the Map window. Note that this function is subsetting the SDR image to only pull in the red, green, and blue bands, as opposed to the previous tutorial where we read in the full hyperspectral cube, and then displayed only the RGB composite in the visParam variable.</p> <p>You can see that the print statements are showing up in the console, displaying the systemID and fileName for each image in the collection. The fileName is applied to the name of the layers in the Map window.</p> <p>You could alter this function to include the visualization paramters, to subset by other bands, or modify it to work for a different image collection. We encourage you to do this on your own!</p>"},{"location":"tutorials/aop-sdr-viz-functions/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to: - Write and call a function to read in and display an AOP SDR image collection - Modify this function to read in other image collections</p>"},{"location":"tutorials/aop-sdr-viz-functions/#requirements","title":"Requirements","text":"<ul> <li>A gmail (@gmail.com) account</li> <li>An Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/</li> <li>A basic understanding of the GEE code editor and the GEE JavaScript API. These are introduced in the tutorials:<ul> <li>Intro to AOP Data in GEE</li> <li>Introduction to AOP Hyperspectral Data in GEE</li> </ul> </li> <li>A basic understanding of hyperspectral data and the AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with the Intro to Working with Hyperspectral Remote Sensing Data in R tutorial. You do not need to follow along with the code in those lessons, but at least read through to gain a better understanding NEON's spectral data products.</li> </ul>"},{"location":"tutorials/aop-sdr-viz-functions/#additional-resources","title":"Additional Resources","text":"<p>If this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start.  *  Get Started with Earth-Engine   *  GEE JavaScript Tutorial   *  Functional Programming in GEE </p>"},{"location":"tutorials/aop-sdr-viz-functions/#get-lesson-code","title":"Get Lesson Code","text":"<p>Function to display AOP SDR Image Collections in GEE</p>"},{"location":"tutorials/interannual-change-analysis/","title":"Exploratory Analysis of Interannual AOP Data in GEE","text":"<p>GEE is a great place to conduct exploratory analysis to better understand the datasets you are working with. In this lesson, we will show how to pull in AOP Surface Directional Reflectance (SDR) datasets, as well as the Ecosystem Structure (CHM) data to look at interannual differences at the site SRER. We will discuss some of the acquisition parameters and other factors that affect data quality and interperatation.</p>"},{"location":"tutorials/interannual-change-analysis/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to:  * Write GEE functions to display map images of AOP SDR, NDVI, and CHM data.  * Create chart images (histogram and line graphs) to summarize data over an area.  * Understand how acquisition parameters may affect the interpretation of data.  * Understand how weather conditions during acquisition may affect reflectance data quality.</p> <p>You will gain familiarity with:  * User-defined GEE functions  * The GEE charting functions (ui.Chart.image)</p>"},{"location":"tutorials/interannual-change-analysis/#requirements","title":"Requirements","text":"<ul> <li>A gmail (@gmail.com) account</li> <li>An Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/</li> <li>A basic understanding of the GEE code editor and the GEE JavaScript API.</li> <li>Optionally, complete the previous GEE tutorials in this tutorial series:<ul> <li>Intro to AOP Data in GEE</li> <li>Introduction to AOP Hyperspectral Data in GEE</li> <li>Intro to GEE Functions</li> </ul> </li> </ul>"},{"location":"tutorials/interannual-change-analysis/#additional-resources","title":"Additional Resources","text":"<p>If this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start.  *  Get Started with Earth-Engine    *  GEE JavaScript Tutorial   *  GEE Charts Image Collection   *  GEE Reducers </p>"},{"location":"tutorials/interannual-change-analysis/#functions-to-read-in-sdr-and-chm-image-collections","title":"Functions to Read in SDR and CHM Image Collections","text":"<p>Let's get started. In this first chunk of code, we are setting the center location of SRER, reading in the SDR image collection, and then creating a function to display the NIS image in GEE. Optionally, we've included lines of code that also calculate and display NDVI from the SDR data, so you can uncomment this and run on your own, if you wish. For more details on how this function works, you can refer to the tutorial Intro to GEE Functions.</p> <pre><code>// Specify center location of SRER\nvar mySite = ee.Geometry.Point([-110.83549, 31.91068])\n\n// Read in the SDR Image Collection\nvar NISimages = ee.ImageCollection('projects/neon/DP3-30006-001_SDR')\n  .filterBounds(mySite)\n\n// Function to display NIS Image + NDVI\nfunction addNISImage(image) {\n  var imageId = ee.Image(image.id); // get the system:id and convert to string\n  var sysID = ee.String(imageId.get(\"system:id\")).getInfo();  // get the system:id - this is an object on the server\n  var fileName = sysID.slice(46,100); // extract the fileName (NEON domain + site code + product code + year)\n  var imageMasked = imageId.updateMask(imageId.gte(0.0000)) // mask out no-data values\n  var imageRGB = imageMasked.select(['band053', 'band035', 'band019']);  // select only RGB bands for display\n\n  Map.addLayer(imageRGB, {min:2, max:20}, fileName, 0)   // add RGB composite to the map, 0 means it is deselected initially\n\n  // uncomment the lines below to calculate NDVI from the SDR and display NDVI\n  // var nisNDVI =imageMasked.normalizedDifference([\"band097\", \"band055\"]).rename(\"ndvi\") // band097 = NIR , band055 = red\n  // var ndviViz= {min:0.05, max:.95,palette:['brown','white','green']}\n\n  // Map.addLayer(nisNDVI, ndviViz, \"NDVI \"+fileName, 0) // optionally add NDVI to the map\n}\n\n// call the addNISimages function to add SDR and NDVI layers to map\nNISimages.evaluate(function(NISimages) {\n  NISimages.features.map(addNISImage);\n})\n</code></pre> <p>Next we can create a similar function for reading in the CHM dataset over all the years. The main differences between this function and the previous one are that 1) it is set to display a single band image, and 2) instead of hard-coding in the minimum and maximum values to display, we dynamically determine them from the data itself, so it will scale appropriately. Note that we can use the <code>.filterMetadata</code> property to select only the CHM data from the DEM image collection, since the CHM is stored in that collection, along with the DTM and DSM.</p> <pre><code>// Read in only the CHM Images (using .filterMetadata by Type)\nvar CHMimages =  ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n  .filterBounds(mySite)\n  .filterMetadata('Type','equals','CHM')\n\n// Function to display Single Band Images setting display range to linear 2%\nfunction addSingleBandImage(image) { // display each image in collection\n  var imageId = ee.Image(image.id); // get the system:id and convert to string\n  var sysID = ee.String(imageId.get(\"system:id\")).getInfo();\n  var fileName = sysID.slice(46,100); // extract the fileName (NEON domain + site code + product code + year)\n  // print(fileName) // optionally print the filename, this will be the name of the layer\n\n  // dynamically determine the range of data to display\n  // sets color scale to show all but lowest/highest 2% of data\n  var pctClip = imageId.reduceRegion({\n    reducer: ee.Reducer.percentile([2, 98]),\n    scale: 10,\n    maxPixels: 3e7});\n\n  var keys = pctClip.keys();\n  var pct02 = ee.Number(pctClip.get(keys.get(0))).round().getInfo()\n  var pct98 = ee.Number(pctClip.get(keys.get(1))).round().getInfo()\n\n  var imageDisplay = imageId.updateMask(imageId.gte(0.0000));\n  Map.addLayer(imageDisplay, {min:pct02, max:pct98}, fileName, 0)\n// print(image)\n}\n\n// call the addSingleBandImage function to add CHM layers to map\n// you could also add all DEM images (DSM/DTM/CHM) but for now let's just add CHM\nCHMimages.evaluate(function(CHMimages) {\n  CHMimages.features.map(addSingleBandImage);\n})\n\n// Center the map on SRER and set zoom level\nMap.setCenter(-110.83549, 31.91068, 11);\n</code></pre> <p>Now that you've read in these two datasets over all the years, we encourage you to explore the different layers and see if you notice any patterns!</p>"},{"location":"tutorials/interannual-change-analysis/#creating-chm-difference-layers","title":"Creating CHM Difference Layers","text":"<p>Next let's create a new raster layer of the difference between the CHMs from 2 different years. We will difference the CHMs from 2018 and 2021 because these years were both collected with the Riegl Q780 system and so have a vertical resolution (CHM height cutoff) of \u2154 m. By contrast the Gemini system (which was used in 2017 and 2020) has a 2m cutoff, so some of the smaller shrubs are not resolved with that sensor. It is important to be aware of factors such as these that may affect the interpretation of the data! We encourage all AOP data users to read the associated metadata pdf documents that are provided with the data products (when downloading from the data portal or using the API).</p> <p>For more information on the vertical resolution, read the footnotes at the end of this lesson.</p> <pre><code>var SRER_CHM2018 = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n  .filterDate('2018-01-01', '2018-12-31')\n  .filterBounds(mySite).first();\n\nvar SRER_CHM2021 = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n  .filterDate('2021-01-01', '2021-12-31')\n  .filterBounds(mySite).first();\n\nvar CHMdiff_2021_2018 = SRER_CHM2021.subtract(SRER_CHM2018);\n// print(CHMdiff_2021_2018)\nMap.addLayer(CHMdiff_2021_2018, {min: -1, max: 1, palette: ['#FF0000','#FFFFFF','#008000']},'CHM diff 2021-2018')\n</code></pre> <p>You can see some broad differences, but there also appear to be some noisy artifacts. We can smooth out some of this noise by using a spatial filter.</p> <pre><code>// Smooth out the difference raster (filter out high-frequency patterns)\n// Define a boxcar or low-pass kernel.\nvar boxcar = ee.Kernel.square({\n  radius: 1.5, units: 'pixels', normalize: true\n});\n\n// Smooth the image by convolving with the boxcar kernel.\nvar smooth = CHMdiff_2021_2018.convolve(boxcar);\nMap.addLayer(smooth, {min: -1, max: 1, palette: ['#FF0000','#FFFFFF','#008000']}, 'CHM diff, smoothed');\n</code></pre>"},{"location":"tutorials/interannual-change-analysis/#chm-difference-histograms","title":"CHM Difference Histograms","text":"<p>Next let's plot histograms of the CHM differences, between 2021-2018 as well as between 2021-2019 and 2019-2018. For this example, we'll just look at the values over a small area of the site. Looking at these 3 sets of years, we will see some of the artifacts related to the lidar sensor used (Riegl Q780 or Optech Gemini). If you didn't know about the differences between the sensors, it would look like the canopy was growing and shrinking from year to year.</p> <p>Before running this chunk of code, you'll need to create a polygon of a region of interest. For this example, I selected a region in the center of the map, shown below, although you can select any region within the site. To create the polygon, select the rectangle out of the shapes in the upper left corner of the map window (hovering over it should say \"Draw a rectangle\"). Then drag the cursor over the area you wish to cover.</p> <p>When you load in this geometry, you should see the <code>geometry</code> variable imported at the top of the code editor window, under Imports. It should look something like this:</p> <p>Once you have this geometry polygon variable set, you can run the following code to generate histograms of the CHM differences over this area.</p> <pre><code>// read in CHMs from 2019 and 2017\nvar SRER_CHM2019 = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n  .filterDate('2019-01-01', '2019-12-31')\n  .filterBounds(mySite).first();\n\nvar SRER_CHM2017 = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n  .filterDate('2017-01-01', '2017-12-31')\n  .filterBounds(mySite).first();\n\n// calculate the CHM difference histograms (2021-2019 &amp; 2019-2018)\nvar CHMdiff_2021_2019 = SRER_CHM2021.subtract(SRER_CHM2019);\nvar CHMdiff_2019_2018 = SRER_CHM2019.subtract(SRER_CHM2018);\n\n// Define the histogram charts for each CHM difference image, print to the console.\nvar hist1 =\n    ui.Chart.image.histogram({image: CHMdiff_2021_2019, region: geometry, scale: 50})\n        .setOptions({title: 'CHM Difference Histogram, 2021-2019',\n                    hAxis: {title: 'CHM Difference (m)',titleTextStyle: {italic: false, bold: true},},\n                    vAxis: {title: 'Count', titleTextStyle: {italic: false, bold: true}},});\nprint(hist1);\n\nvar hist2 =\n    ui.Chart.image.histogram({image: CHMdiff_2019_2018, region: geometry, scale: 50})\n        .setOptions({title: 'CHM Difference Histogram, 2019-2018',\n                    hAxis: {title: 'CHM Difference (m)',titleTextStyle: {italic: false, bold: true},},\n                    vAxis: {title: 'Count', titleTextStyle: {italic: false, bold: true}},});\nprint(hist2);\n\nvar hist3 =\n    ui.Chart.image.histogram({image: CHMdiff_2021_2018, region: geometry, scale: 50})\n        .setOptions({title: 'CHM Difference Histogram, 2021-2018',\n                    hAxis: {title: 'CHM Difference (m)',titleTextStyle: {italic: false, bold: true},},\n                    vAxis: {title: 'Count', titleTextStyle: {italic: false, bold: true}},});\nprint(hist3);\n</code></pre> <p>Let's take a minute to understand what's going on here. In each case, we subtracted the earlier year from the later year. So from 2019 to 2021, it looks like the vegetation grew on average by ~0.6m, but from 2018 to 2019 it shrunk by the same amount. This is because in 2021 there was a lower vertical cutoff, so shrubs of at least 0.67m were resolved, where before anything below 2m was obscured. These low shrubs are likely the dominant source of the change we're seeing. We can see the same pattern, but in reverse between 2018 and 2019. The difference histogram from 2021 to 2018 more accurately represents the change, which is centered around 0, and the map we displayed shows local changes in certain areas, related to actual vegetation growth and ecological drivers. Note that 2021 was a particularly wet year, and AOP's flight was in optimal peak greenness, as you can see when comparing the SDR imagery to earlier years.</p>"},{"location":"tutorials/interannual-change-analysis/#ndvi-time-series","title":"NDVI Time Series","text":"<p>Last but not least, we can take a quick look at NDVI changes over the four years of data. A quick way to look at the interannual changes are to make a line plot, which we'll do shortly. First let's take a step back and see the weather conditions during the collections. For every mission, the AOP flight operators assess the cloud conditions and note whether the cloud clover is &lt;10% (green), 10-50% (yellow), or &gt;50% (red). This information gets passed through to the reflectance hdf5 data, and is also available in the summary metadata documents, delivered with all the spectrometer data products. The weather conditions have direct implications for data quality, and while we strive to collect data in \"green\" weather conditions, it is not always possible, so the user must take this into consideration when working with the data.</p> <p>The figure below shows the weather conditions at SRER for each of the 4 collections. In 2017 and 2021, the full site was collected in &lt;10% cloud conditions, while in 2018 and 2019 there were mixed weather conditions. However, for all four years, the center of the site was collected in optimal cloud conditions.</p> <p>With this in mind, let's use the same geometry we used before, centered in the middle of the plot, to look at the mean NDVI over the four years in a small part of the site. Here's the GEE code for doing this:</p> <pre><code>// calculate NDVI for the geometry\nvar ndvi = NISimages.map(function(image) {\n    var ndviClip = image.clip(geometry)\n    return ndviClip.addBands(ndviClip.normalizedDifference([\"band097\", \"band055\"]).rename('NDVI'))\n});\n\n// Create a time series chart, with image, geometry &amp; median reducer\nvar plotNDVI = ui.Chart.image.seriesByRegion(ndvi, geometry, ee.Reducer.median(),\n              'NDVI', 100, 'system:time_start') // band, scale, x-axis property\n              .setChartType('LineChart').setOptions({\n                title: 'Median NDVI for Selected Geometry',\n                hAxis: {title: 'Date'},\n                vAxis: {title: 'NDVI'},\n                legend: {position: \"none\"},\n                lineWidth: 1,\n                pointSize: 3\n});\n\n// Display the chart\nprint(plotNDVI);\n</code></pre> <p>We can see how much NDVI has increased in 2021 relative to the earlier years, which makes sense when we look at the reflectance RGB composites - it is much greener in 2021! While this line plot doesn't show us a lot of information now, as the AOP data set builds up in years to come, this may become a more interesting figure.</p> <p>On your own, we encourage you to dig into the code from this tutorial and modify according to your scientific interests. Think of some questions you have about this dataset, and modify these functions or try writing your own function to answer your question. For example, try out a different reducer, repeat the plots for different areas of the site, and see if there are any other datasets that you could bring in to help you with your analysis. You can also pull in satellite data and see how the NEON data compares. This is just the starting point!</p>"},{"location":"tutorials/interannual-change-analysis/#get-lesson-code","title":"Get Lesson Code","text":"<p>AOP GEE Internannual Change Exploratory Analysis</p>"},{"location":"tutorials/interannual-change-analysis/#footnotes","title":"Footnotes","text":"<ul> <li>To download the metadata documentation without downloading all the data products, you can go through the process of downloading the data product, and when you get to the files, select only the \".pdf\" extension. The Algorithm Theoretical Basis Documents (ATBDs), which can be downloaded either from the data product information page or from the data portal, also discuss the uncertainty and important information pertaining to the data.</li> <li>The vertical resolution is related to the outgoing pulse width of the lidar system. Optech Gemini has a 10ns outgoing pulse, while the Riegl Q780 and Optech Galaxy Prime sensors have a 3ns outgoing pulse width. At the nominal flying altitude of 1000m AGL, 10ns translates to a range resolution of ~2m, while 3ns corresponds to \u2154m.</li> <li>From 2021 onward, all NEON lidar collections have the improved vertical resolution of .67m, as NEON started operating the Optech Galaxy Prime, which replaced one of the Optech Gemini sensors. This has a 3ns outgoing pulse width, matching the Riegl Q780 system.</li> </ul>"},{"location":"tutorials/intro-aop-sdr-data/","title":"Introduction to AOP Hyperspectral Data in GEE","text":""},{"location":"tutorials/intro-aop-sdr-data/#read-in-and-visualize-aop-sdr-data","title":"Read in and Visualize AOP SDR Data","text":"<p>In the first Intro to AOP data in GEE tutorial, we showed how to explore the NEON AOP GEE Image Collections. We will build off that tutorial in this lesson, to pull in and visualize some AOP hyperspectral data in GEE. Specifically, we will look at surface directional reflectance (SDR) data collected at the NEON site SRER (Santa Rita Experimental Range) for 3 years between 2018 and 2021.</p> <p>Let's get started! In this tutorial we generate basic GEE (JavaScript) code to visualize hyperspectral data. We will work through the following steps:</p> <p>1) Pull in an AOP hyperspectral (SDR) image 2) Set the visualization parameters 3) Mask the no data values 4) Add the AOP SDR layer to the GEE Map 5) Center on the region of interest and set zoom level</p> <p>We encourage you to follow along with this code chunks in this exercise in your code editor. To run the cells, you can click the Run button at the top of the code editor. Note that until you run the last two steps (adding the data layer to the map), you will not see the AOP data show up in the Interactive Map.</p>"},{"location":"tutorials/intro-aop-sdr-data/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to: - Read AOP hyperspectral reflectance raster data sets into GEE - Visualize multiple years of data and qualitatively explore inter-annual differences</p>"},{"location":"tutorials/intro-aop-sdr-data/#requirements","title":"Requirements","text":"<ul> <li>A gmail (@gmail.com) account</li> <li>An Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/</li> <li>A basic understanding of the GEE code editor and the GEE JavaScript API. These are introduced in the tutorial Intro to AOP Data in GEE, as well as in the Additional Resources below.</li> <li>A basic understanding of hyperspectral data and the AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with the Intro to Working with Hyperspectral Remote Sensing Data in R tutorial. You do not need to follow along with the code in those lessons, but at least read through to gain a better understanding NEON's spectral data products.</li> </ul>"},{"location":"tutorials/intro-aop-sdr-data/#additional-resources","title":"Additional Resources","text":"<p>If this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start.  *  Get Started with Earth-Engine    *  GEE JavaScript Tutorial </p>"},{"location":"tutorials/intro-aop-sdr-data/#read-in-the-srer-2018-sdr-image","title":"Read in the SRER 2018 SDR image","text":"<p>Using <code>ee.Image</code>, you can pull in a single image if you know the path and name of the image (as opposed to filtering down to the individual images from an image collection). If you don't know this path, you can pull in the image collection and look at the Asset Details &gt; Images tab. We will assign this image to a variable (var) called <code>SRER_SDR2018</code>. You can refer to the tables in the Data Access and Availability section, in the Intro to AOP data in GEE tutorial, to see how to pull in spectral data from a different site or date.</p> <pre><code>var SRER_SDR2018 = ee.Image(\"projects/neon/D14_SRER/L3/DP3-30006-001_D14_SRER_SDR_2018\");\n</code></pre> <p>As we covered in the previous lesson, when you type this code, it will be underlined in red (the same as you would see with a mis-spelled word). When you hover over this line, you will see an option pop up that says <code>\"SRER_SDR2018\" can be converted to an import record. Convert Ignore</code></p> <p>If you click <code>Convert</code>, the line of code will disappear and the variable will be pulled into the top of the code editor, as shown below. Once imported, you can interactively explore this variable - eg. you can expand on the <code>bands</code> and <code>properties</code> to gain more information about this image, or \"asset\", as it's called in GEE.</p> <p>Another way to learn more about this asset is to left-click on the blue <code>projects/neon/D14_SRER/L3_DP3-30006-001-D14_SRER_SDR_2018</code>. This will pop up a box with more detailed information about this asset, as shown below:</p> <p>Click <code>Esc</code> to return to the code editor. Note that you can run the code either way, with the variable explicitly specified in the code editor, or imported as a variable, but we encourage you to leave the variable written out in the code, as this way is more reproducible.</p>"},{"location":"tutorials/intro-aop-sdr-data/#set-the-visualization-parameters","title":"Set the visualization parameters","text":"<p>The visualization parameters specifies the band combination that is displayed, and other display options, such as the minimum and maximum values for the histogram stretch. For more detailed information, refer to the GEE documentation on image visualization.</p> <p>To set the visualization parameters, we will create a new variable (called <code>visParams</code>). This variable is applied to the layer and determines what is displayed. In this we are setting the RGB bands to display - for this exercise we are setting them to red, green, and blue portions of the spectrum in order to show a True Color Image. You can change these bands to show a False Color Image or any band combination of interest. You can refer to NEON's lessons on Multi-Band Rasters in R or RGB and False Color Images in Python for more background on band stacking.</p> <pre><code>var visParams = {'min':2,'max':20,'gamma':0.9,'bands':['band053','band035','band019']};\n</code></pre>"},{"location":"tutorials/intro-aop-sdr-data/#mask-the-no-data-values","title":"Mask the no data values","text":"<p>This step is optional, but recommended. AOP sets No Data Values to -9999, so if you don't mask these out you will see any missing data as black in the image (this will often result in a black boundary surrounding the site, but if any data is missing inside the site that will show up as black as well). To show only the data that was collected, we recommend masking these values using the <code>updateMask</code> function, keeping only values greater than or equal to zero, as shown below:</p> <pre><code>var SRER_SDR2018mask = SRER_SDR2018.updateMask(SRER_SDR2018.gte(0.0000));\n</code></pre>"},{"location":"tutorials/intro-aop-sdr-data/#add-sdr-layer-to-the-map","title":"Add SDR layer to the map","text":"<p>Now that we've defined the data, the visualization parameters, and the mask, we can add the reflectance layer to the Map! To do this, we use the <code>Map.addLayer</code> function with our masked data variable, <code>SRER_SDRmask</code>, using the <code>visParams</code> and assign this layer a label, which will show up in the Map.</p> <pre><code>Map.addLayer(SRER_SDR2018mask, visParams, 'SRER 2018');\n</code></pre>"},{"location":"tutorials/intro-aop-sdr-data/#center-the-map-on-our-area-of-interest-and-set-zoom-level","title":"Center the map on our area of interest and set zoom level","text":"<p>GEE by default does not know where we are interested in looking. We can center the map over our new data layer by specifiying <code>Map.setCenter</code> with the longitude, latitude, and zoom level (for this site, zoom of 11 works well to show the full site, but you can try other values to see how the image size changes).</p> <pre><code>Map.setCenter(-110.83549, 31.91068, 11);\n</code></pre>"},{"location":"tutorials/intro-aop-sdr-data/#putting-it-all-together","title":"Putting it All Together","text":"<p>The following code chunk runs all the steps we just broke down, and also adds in 2 more years of data (2019 and 2021). You can pull in this code into your code editor by clicking here, or alternately copy and paste the code below into your GEE code editor. Click Run to add the 3 SDR data layers for each year.</p> <pre><code>// This script pulls in hyperspectral data over the Santa Rita Experimental Range (SRER)\n// from 2018, 2019, and 2021 and plots RGB 3-band composites\n\n// Read in Surface Directional Reflectance (SDR) Images\nvar SRER_SDR2018 = ee.Image(\"projects/neon/D14_SRER/L3/DP3-30006-001_D14_SRER_SDR_2018\");\nvar SRER_SDR2019 = ee.Image(\"projects/neon/D14_SRER/L3/DP3-30006-001_D14_SRER_SDR_2019\");\nvar SRER_SDR2021 = ee.Image(\"projects/neon/D14_SRER/L3/DP3-30006-001_D14_SRER_SDR_2021\");\n\n// Set the visualization parameters so contrast is maximized, and set display to show RGB bands\nvar visParams = {'min':2,'max':20,'gamma':0.9,'bands':['band053','band035','band019']};\n\n// Mask layers to only show values &gt; 0 (this hides the no data values of -9999)\nvar SRER_SDR2018mask = SRER_SDR2018.updateMask(SRER_SDR2018.gte(0.0000));\nvar SRER_SDR2019mask = SRER_SDR2019.updateMask(SRER_SDR2019.gte(0.0000));\nvar SRER_SDR2021mask = SRER_SDR2021.updateMask(SRER_SDR2021.gte(0.0000));\n\n// Add the 3 years of SRER SDR data as layers to the Map:\nMap.addLayer(SRER_SDR2018mask, visParams, 'SRER 2018');\nMap.addLayer(SRER_SDR2019mask, visParams, 'SRER 2019');\nMap.addLayer(SRER_SDR2021mask, visParams, 'SRER 2021');\n\n// Center the map on SRER &amp; zoom to desired level (11 = zoom level)\nMap.setCenter(-110.83549, 31.91068, 11);\n</code></pre> <p>Once you have the three years of data added, you can look at the different years one at a time by selecting each layer in the Layers box inside the Map:</p> <p>If you click anywhere inside the AOP map (where there is data), you will see the 426 spectral bands as a bar chart displayed for each of the layers in the Inspector window (top-right corner of the code editor). You can see the spectral values for different layers by clicking on the arrow to the left of the layer name under Pixels (eg. SRER 2018). Note that these values are just shown as band #s, and you can't tell from the chart what the actual wavelength values are. We will convert the band numbers to wavelengths in the next lesson, so stay tuned!</p>"},{"location":"tutorials/intro-aop-sdr-data/#get-lesson-code","title":"Get Lesson Code","text":"<p>Importing and Visualizing SRER SDR Data</p>"},{"location":"tutorials/plot-spectra/","title":"Plot spectral signatures of AOP SDR data in GEE","text":""},{"location":"tutorials/plot-spectra/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to: - Read in a single AOP Hyperspectral Reflectance raster data set at the NEON site SRER - Link spectral band #s to wavelength values - Gain experience with the Earth Engine User Interface API - Create a plot to display the spectral signature of a given pixel upon clicking</p>"},{"location":"tutorials/plot-spectra/#requirements","title":"Requirements","text":"<ul> <li>Complete the following introductory AOP GEE tutorials:<ul> <li>Intro to AOP Data in GEE</li> <li>Intro to AOP Hyperspectral Data in GEE</li> </ul> </li> <li>An understanding of hyperspectral data and AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with the Intro to Working with Hyperspectral Remote Sensing Data tutorial. You do not need to follow along with the code in those lessons, but at least read through to gain a better understanding NEON's spectral data products.</li> </ul>"},{"location":"tutorials/plot-spectra/#read-in-the-aop-sdr-2021-dataset-at-srer","title":"Read in the AOP SDR 2021 Dataset at SRER","text":"<p>We will start at our ending point of the last tutorial. For this exercise we will only read data from 2021:</p> <pre><code>// This script pulls in hyperspectral data over the Santa Rita Experimental Range (SRER)\n// from 2021 and plots RGB 3-band composite of the imagery\n\n// Read in Surface Directional Reflectance (SDR) Images\nvar SRER_SDR2021 = ee.Image(\"projects/neon/D14_SRER/L3/DP3-30006-001_D14_SRER_SDR_2021\");\n\n// Set the visualization parameters so contrast is maximized, and set display to show RGB bands\nvar visParams = {'min':2,'max':20,'gamma':0.9,'bands':['band053','band035','band019']};\n\n// Mask layer to only show values &gt; 0 (this hides the no data values of -9999)\nvar SRER_SDR2021mask = SRER_SDR2021.updateMask(SRER_SDR2021.gte(0.0000));\n\n// Add the 2021 SRER SDR data as layers to the Map:\nMap.addLayer(SRER_SDR2021mask, visParams, 'SRER 2021');\n</code></pre>"},{"location":"tutorials/plot-spectra/#create-the-wavelengths-variable","title":"Create the wavelengths variable","text":"<p>In the last tutorial, we ended by viewing a bar chart of the reflectance values v. band #, but we couldn't see the wavelengths corresponding to those bands. Here we set a wavelengths variable (var) that we will apply to generate a spectral plot (wavelengths v. reflectance). To add this wavelength information, we will use the <code>ee.List.sequence</code> function, which is used as follows: <code>ee.List.sequence(start, end, step, count)</code> to \"generate a sequence of numbers from start to end (inclusive) in increments of step, or in count equally-spaced increments.\"</p> <pre><code>// Set wavelength variable for spectral plot\nvar wavelengths = ee.List.sequence(381, 2510, 5).getInfo()\nvar bands_no =  ee.List.sequence(1, 426).getInfo()\n</code></pre>"},{"location":"tutorials/plot-spectra/#earth-engine-user-interface","title":"Earth Engine User Interface","text":"<p>Next, we'll use the Earth Engine User Interface to create a panel that will hold our spectral plot. We'll use the ui.Panel function for this:</p> <pre><code>// Create a panel to hold the spectral signature plot\nvar panel = ui.Panel();\npanel.style().set({width: '600px',height: '300px',position: 'top-left'});\nMap.add(panel);\nMap.style().set('cursor', 'crosshair');\n</code></pre>"},{"location":"tutorials/plot-spectra/#creating-an-interactive-spectral-plot","title":"Creating an Interactive Spectral Plot","text":"<p>Now we'll set up an interactive function using Map.onClick that will generate a plot whenever a user clicks on the map:</p> <pre><code>// Create a function to draw a chart when a user clicks on the map.\nMap.onClick(function(coords) {\n  panel.clear();\n  var point = ee.Geometry.Point(coords.lon, coords.lat);\n  var chart = ui.Chart.image.regions(SRER_SDR2021, point, null, 1, '\u03bb (nm)', wavelengths);\n    chart.setOptions({title: 'SRER 2021 Reflectance',\n                      hAxis: {title: 'Wavelength (nm)',\n                      vAxis: {title: 'Reflectance'},\n                      gridlines: { count: 5 }}\n                              });\n    // Create and update the location label\n  var location = 'Longitude: ' + coords.lon.toFixed(2) + ' ' +\n                 'Latitude: ' + coords.lat.toFixed(2);\n  panel.widgets().set(1, ui.Label(location));\n  panel.add(chart);\n});\n</code></pre> <p>Finally, we'll add the SRER data layer and center on that layer. Here we use the <code>Map.centerObject</code> function to center on our SRER_SDR2021 object.</p> <pre><code>// Add the 2021 SRER SDR data as a layer to the Map:\nMap.addLayer(SRER_SDR2021mask, visParams, 'SRER 2021');\n\nMap.centerObject(SRER_SDR2021,11)\n</code></pre> <p>When you run this code, linked here, you will see the SRER SDR layer show up in the Map panel, along with a blank figure outline. When you click anywhere in this image, the figure will be populated with the spectral signature of the pixel you clicked on.</p>"},{"location":"tutorials/plot-spectra/#get-lesson-code","title":"Get Lesson Code","text":"<p>Plot Spectral Signatures of AOP SDR Data</p>"}]}