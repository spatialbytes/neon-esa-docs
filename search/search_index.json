{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NEON Workshop","text":"<p>This page uses a custom template and will display the workshop landing page.</p>"},{"location":"neon-aop-gee/","title":"NEON Airborne Remote Sensing in GEE Tutorials","text":"<p>Open Science Initiative</p> <p>Welcome to the NEON Airborne Remote Sensing in Google Earth Engine Resources workshop! This community-driven resource provides comprehensive tutorials for working with AOP raster data products in Google Earth Engine.</p>"},{"location":"neon-aop-gee/#about-this-repository","title":"About This Repository","text":"<p>This repository offers hands-on tutorials to help researchers, students, and practitioners work with NEON Airborne Observation Platform (AOP) data products in Google Earth Engine. Our tutorials cover data generated from three primary sensors:</p> <ul> <li> <p> Hyperspectral Imaging</p> <p>High-resolution spectral data for vegetation analysis and species classification</p> <p>426 spectral bands | 1m spatial resolution</p> </li> <li> <p> LiDAR Sensors</p> <p>3D structural data for canopy height and biomass estimation</p> <p>Point clouds | Derived products</p> </li> <li> <p> RGB Camera</p> <p>High-resolution imagery for visual context and ground truthing</p> <p>10cm spatial resolution | True color</p> </li> </ul>"},{"location":"neon-aop-gee/#repository-status","title":"Repository Status","text":"<p>Active Development</p> <p>This repository is publicly available in the interest of open science but remains under active development.</p> <ul> <li> Check the changelog for recent updates</li> <li> Community contributions are welcome</li> <li> Report issues via GitHub Issues</li> </ul>"},{"location":"neon-aop-gee/#open-science-commitment","title":"Open Science Commitment","text":"<p>We believe in making scientific tools and knowledge accessible to all. This repository reflects our commitment to:</p> <ul> <li>Transparency in data processing workflows</li> <li>Reproducible research methodologies</li> <li>Community-driven development and improvement</li> <li>Educational resources for all skill levels</li> </ul>"},{"location":"neon-aop-gee/#contact-support","title":"Contact &amp; Support","text":""},{"location":"neon-aop-gee/#neon-airborne-observation-platform","title":"NEON Airborne Observation Platform","text":"<p>Primary Contact</p> <p>Organization: National Ecological Observatory Network Airborne Observation Platform (NEON AOP)\u00b9</p> <p> Website: neonscience.org</p> <p>Contact Options:</p> <p> General Contact Form</p> <p> AOP GEE List</p>"},{"location":"neon-aop-gee/#spatial-bytes","title":"Spatial Bytes","text":"<p>Development Partner</p> <p>Website: https://contact.spatialbytes.work/</p> <p>Contact: Information Available Soon</p> <p>Funding Acknowledgment</p> <p>\u00b9 NEON is a project fully funded by the National Science Foundation and operated by Battelle.</p>"},{"location":"old_index/","title":"Working with NEON Airborne Remote Sensing Data in Google Earth Engine","text":"<p>Workshop Overview</p> <p>Learn to harness the power of NEON's airborne remote sensing data through hands-on exercises in Google Earth Engine. This workshop combines ecological insights with cutting-edge cloud computing for regional-scale environmental analysis.</p>"},{"location":"old_index/#about-this-workshop","title":"About This Workshop","text":"<p>The U.S. NSF's National Ecological Observatory Network (NEON) offers extensive ecological data across various temporal and spatial scales. NEON's Airborne Observation Platform (AOP) captures high-resolution hyperspectral imagery, lidar, and RGB photography at 81 U.S. sites, with data spanning 2-10 years. </p> <p>In 2024, 5 AOP datasets were added to the Google Earth Engine publisher catalog, providing another means of accessing and working with NEON data.</p>"},{"location":"old_index/#what-youll-learn","title":"What You'll Learn","text":"Remote Sensing FundamentalsGoogle Earth Engine SkillsMachine Learning Applications <ul> <li>Work with hyperspectral imagery and lidar data</li> <li>Understand spectral signatures and vegetation indices</li> <li>Apply quality assurance best practices</li> </ul> <ul> <li>Set up and navigate the GEE environment</li> <li>Access NEON datasets programmatically</li> <li>Scale analysis from site to regional level</li> </ul> <ul> <li>Integrate ground-based field data</li> <li>Build classification models</li> <li>Generate regional-scale predictions</li> </ul>"},{"location":"old_index/#learning-objectives","title":"Learning Objectives","text":"<ul> <li> Understand NEON AOP data structure and applications</li> <li> Master Google Earth Engine workflows for ecological data</li> <li> Apply quality assurance considerations for remote sensing</li> <li> Integrate field and remote sensing data for machine learning</li> </ul>"},{"location":"old_index/#workshop-schedule","title":"Workshop Schedule","text":"Time  Session  Instructor(s) 11:45 AM Welcome &amp; Introductions Bridget Hass, Kate Murphy, Sam Roy 11:50 AM NEON Airborne Observation Platform Overview Bridget Hass &amp; Kate Murphy 12:05 PM Setting up Google Earth Engine Sam Roy 12:15 PM Lesson 1: Download &amp; Explore Hyperspectral Data Bridget Hass 12:35 PM Lesson 2: Reflectance QA Considerations Bridget Hass 12:55 PM Lesson 3: Hyperspectral Classification Sam Roy 1:05 PM Discussion &amp; Wrap-up All Instructors <p>Duration</p> <p>Total Workshop Time: 1 hour 20 minutes Format: Interactive live-coding sessions</p>"},{"location":"old_index/#prerequisites","title":"Prerequisites","text":"<p>What You Need</p> <ul> <li> Basic familiarity with remote sensing concepts</li> <li> Google account for Earth Engine access</li> <li> Web browser (Chrome recommended)</li> <li> Curiosity about ecological applications!</li> </ul>"},{"location":"old_index/#datasets-featured","title":"Datasets Featured","text":"Dataset Type Resolution Coverage Applications Hyperspectral Imagery 1m spatial, 426 bands All NEON sites Vegetation analysis, species classification LiDAR Point Clouds High-density 3D Structural mapping Canopy height, biomass estimation RGB Photography 10cm spatial Visual context Ground truthing, feature identification"},{"location":"old_index/#meet-your-instructors","title":"Meet Your Instructors","text":"<p>Expert Team</p> <p>Bridget Hass - NEON AOP Specialist Expertise in hyperspectral remote sensing and ecological applications</p> <p>Kate Murphy - NEON AOP Data Scientist Focus on airborne data processing and quality assurance</p> <p>Sam Roy - Google Earth Engine Developer Specializes in cloud-based remote sensing workflows</p>"},{"location":"old_index/#quick-links","title":"Quick Links","text":"<ul> <li> <p> Google Earth Engine</p> <p>Access the cloud computing platform</p> <p> Sign up for GEE</p> </li> <li> <p> NEON Data Portal</p> <p>Explore all NEON datasets</p> <p> Browse Data</p> </li> <li> <p> Workshop Materials</p> <p>Code examples and tutorials</p> <p> GitHub Repository</p> </li> <li> <p> Documentation</p> <p>Detailed guides and references</p> <p> API Documentation</p> </li> </ul>"},{"location":"old_index/#faq","title":"FAQ","text":"Do I need programming experience? <p>Basic familiarity with JavaScript or Python is helpful but not required. We'll provide code examples and walk through each step.</p> What if I don't have a Google Earth Engine account? <p>We'll help you set up access during the workshop. Make sure you have a Google account ready.</p> Can I access the materials after the workshop? <p>Yes! All code examples and datasets will remain available through the NEON Data Portal and GitHub repository.</p> What ecological applications will we cover? <p>Focus areas include vegetation classification, biodiversity monitoring, and ecosystem health assessment using spectral analysis.</p>"},{"location":"old_index/#material-contact-mail-contact-support","title":":material-contact-mail: Contact &amp; Support","text":"<p>Get in Touch</p> <p>NEON Airborne Observation Platform National Science Foundation Project - Operated by Battelle</p> <p> Website: neonscience.org Contact: NEON Contact Form Support: Available throughout the workshop</p> <p>Ready to Start?</p> <p>Join us for an exciting journey into the world of airborne remote sensing and ecological data science! </p>"},{"location":"background/aop_background/","title":"NEON Airborne Observation Platform","text":""},{"location":"background/aop_background/#neon-airborne-observation-platform-aop","title":"NEON Airborne Observation Platform (AOP)","text":"NEON Airborne Remote Sensing"},{"location":"background/aop_background/#aop-payload-sensors","title":"AOP Payload Sensors","text":"<p>The AOP consists of three complete and comparable instrument payloads. Typically, two of the payloads are dedicated to collections of the NEON field sites while the third is dedicated to NEON's Research Support services which support externally driven research. The primary sensors on each payload include:</p> <ol> <li>A discrete and full-waveform lidar to provide three-dimensional structural information of the landscape</li> <li>An imaging spectrometer to allow discrimination of land cover types and chemical content of vegetation</li> <li>A high-resolution digital camera to provide spatially accurate and detailed contextual information</li> <li>A GPS antenna and receiver and Inertial Measurement Unit (IMU) to provide high-accuracy positioning and orientation of the aircraft</li> </ol>"},{"location":"background/aop_background/#aop-data-products","title":"AOP Data Products","text":"<p>The AOP produces approximately 30 data products. The products are separated into categories of Level 1, Level 2, and Level 3 (L1, L2, L3). L1 represents the least processed data products. Additional processing steps are required to transition the L1 data to the derived L2 and L3 data. Broadly, the L1 and L2 products are provided by individual aircraft flight line, while L3 products are provided in 1 km by 1 km tiles. Generally, the data volume for L1 products is the highest and decreases for L2 and L3 products.</p> <p>Data Access</p> <p>Details of the different products within each Level can be found in the individual webpages for each sensor. All AOP data products can be found on the NEON Data Portal, and a subset of the L3 data products are available on Google Earth Engine.</p>"},{"location":"background/aop_background/#imaging-spectrometer-data-products","title":"Imaging Spectrometer Data Products","text":"<p>Level 1 (L1) products include at-sensor radiance and surface reflectance which are distributed by flightline. The image data is georeferenced to the ITRF00 datum and projected into the appropriate UTM zone, and provided at 1 m spatial resolution. Both the radiance and reflectance image data are stored in an HDF5 file format that includes extensive metadata and data quality information. The HDF5 format was selected because of the flexibility it allows in storing associated metadata.</p> <p>Level 2 (L2) products are derived from the L1 surface reflectance and are produced at the same spatial resolution (1 m), datum and map projection as the Level 1 products. The L2 products include a suite of spectral indices designed to strategically combine bands to highlight vegetation characteristics such as photosynthetic activity or water content. For example, NDVI (Normalized Difference Vegetation Index) is a well-known and commonly used vegetation index which combines information from the NIR and Red regions to estimate vegetative greenness and can be used as a proxy for plant health. The L2 products also include fPAR (fraction of photosynthetically active radiation) and LAI (leaf area index), products further derived from vegetation indices. Additionally, a surface Albedo product that estimates the integrated reflectance of all the NIS bands into a single value is also provided. All L2 products are distributed by flightline in a GeoTIFF (gtiff) format. Currently, all vegetation indices, water indices, fPAR, and LAI are delivered with associated simulated error images.</p> <p>Level 3 (L3) products include mosaics of all L1 and L2 products, excluding at-sensor radiance, and are distributed as 1 km x 1 km tiles instead of flightlines. Tiles are created by making a full mosaic of all the data and sub-setting the 1 km x 1 km tiles. The tiles are designed so their boundaries are set to even 1000 m UTM coordinate intervals. During the mosaic generation, the algorithm preferentially selects pixels that were collected under the best weather conditions in regions with multiple potential pixels due to flightline overlap. If weather conditions were equivalent, pixels acquired nearest to nadir of the image acquisition are selected. Generally, this will correspond to pixels that are nearest to the center of the flightline. The tiles are created at the same spatial resolution (1 m) as the L1 and L2 products are in delivered in gtiff format, with the exception of the surface reflectance, which is delivered in HDF5 format.</p>"},{"location":"background/aop_background/#brdf-and-topographic-corrections","title":"BRDF and Topographic Corrections","text":"<p>BRDF Corrections Available</p> <p>Starting in 2024, NEON began producing BRDF (Bidirectional Reflectance Distribution Function) and topographic corrected reflectance data, which include \"bidirectional\" in the name, and end with revision .002 in the Data Product IDs.</p> <p>As of 2025, these bidirectional reflectance are currently only available for data collected between 2022-2024. NEON is beginning to back-process earlier years (pre-2022) to apply the BRDF and topographic corrections. Please look at the data availability charts for each product on the data portal to determine whether the bidirectional data are available. Eventually, only bidirectional data products will be delivered, with the exception of the Level 1 Spectrometer orthorectified surface directional reflectance (DP1.30006.001), which will continue to be delivered, so that researchers who wish to carry out their own BRDF, topographic, or other corrections may do so.</p> <p>The table below shows a full list of NEON's spectrometer-derived data products, including the corresponding bidirectional reflectance data products, if applicable.</p> <p>Table 1: NEON AOP Imaging Spectrometer Datasets</p> Product Name Level Data Product ID (DPID) BRDF-Corrected DPID Spectrometer orthorectified at-sensor radiance L1 DP1.30008.001 - Spectrometer orthorectified surface (bi)directional reflectance L1 DP1.30006.001 DP1.30006.002 Albedo - spectrometer - flightline L2 DP2.30011.001 DP2.30011.002 LAI - spectrometer - flightline L2 DP2.30012.001 DP2.30012.002 fPAR - spectrometer - flightline L2 DP2.30014.001 DP2.30014.002 Canopy water indices - flightline L2 DP2.30019.001 DP2.30019.002 Vegetation indices - spectrometer - flightline L2 DP2.30026.001 DP2.30026.002 Albedo - spectrometer - mosaic L3 DP3.30011.001 DP3.30011.002 LAI - Spectrometer - mosaic L3 DP3.30012.001 DP3.30012.002 fPAR - spectrometer - mosaic L3 DP3.30014.001 DP3.30014.002 Canopy water indices - mosaic L3 DP3.30019.001 DP3.30019.002 Vegetation indices - spectrometer - mosaic L3 DP3.30026.001 DP3.30026.002 <p>In addition to the spectrometer-derived data products, NEON generates 5 lidar-derived products and 2 RGB camera data products, summarized below. These data products provide valuable structural and visual information that compliment the spectrometer data.</p>"},{"location":"background/aop_background/#lidar-data-products","title":"LiDAR Data Products","text":"<p>Table 2: NEON AOP Lidar Datasets</p> Product Name Level Data Product ID (DPID) ATBD Document # LiDAR Slant Range Waveform L1 DP1.30001.001 NEON.DOC.001293 Discrete Return LiDAR Point Cloud L1 DP1.30003.001 NEON.DOC.001292, NEON.DOC.001288 Ecosystem Structure L3 DP3.30015.001 NEON.DOC.002387 Elevation \u2013 LiDAR L3 DP3.30024.001 NEON.DOC.002390 Slope and Aspect \u2013 LiDAR L3 DP3.30025.001 NEON.DOC.003791"},{"location":"background/aop_background/#rgb-camera-products","title":"RGB Camera Products","text":"<p>Table 3: NEON AOP Camera Datasets</p> Product Name Level Data Product ID (DPID) ATBD Document # High-resolution orthorectified camera imagery L1 DP1.30010.001 NEON.DOC.001211vB High-resolution orthorectified camera imagery mosaic L3 DP3.30010.001 NEON.DOC.005052vB"},{"location":"background/aop_background/#summary","title":"Summary","text":"<p>The NEON Airborne Observation Platform represents a cutting-edge approach to continental-scale ecological monitoring, providing researchers with unprecedented access to high-resolution, standardized remote sensing data across diverse ecosystems. The integration of lidar, imaging spectrometry, and high-resolution camera systems creates a comprehensive dataset that enables detailed analysis of ecosystem structure, function, and change over time.</p> <p>The multi-level data processing approach (L1, L2, L3) ensures that researchers can access data at the appropriate level of processing for their specific research needs, from raw sensor measurements to analysis-ready mosaicked products. The recent addition of BRDF and topographic corrections further enhances the scientific value of these datasets by improving comparability across different viewing and illumination conditions.</p> <p>Getting Started</p> <p>To begin working with NEON AOP data, visit the NEON Data Portal to explore available datasets, or check out the Google Earth Engine catalog for cloud-based analysis of L3 products.</p> <p>Additional Resources</p> <p>For detailed technical information about data processing algorithms and product specifications, refer to the ATBD (Algorithm Theoretical Basis Document) numbers listed in the tables above, available through the NEON Data Portal.</p>"},{"location":"background/neon_aop_gee_data/","title":"Introduction to AOP Data in Google Earth Engine (GEE)","text":"<p>AOP has published a subset of AOP Level 3 (mosaicked) data products at 5 NEON sites (as of Spring 2022) on GEE. This data has been converted to Cloud Optimized GeoTIFF (COG) format. NEON L3 lidar and derived spectral indices are available in geotiff raster format, so are relatively straightforward to add to GEE, however the hyperspectral data is available in hdf5 (hierarchical data) format, and have been converted to the COG format prior to being added to GEE.</p> <p>The NEON data products that have been made available on GEE can be accessed through the <code>projects/neon</code> folder with an appended prefix of the Data Product ID, matching the NEON data portal. The table below summarizes the prefixes to use for each data product, and is a useful reference for reading in AOP GEE datasets. You will see how to access and read in these data products in the next part of this lesson.</p> Acronym Data Product Data Product ID (Prefix) SDR Surface Directional Reflectance DP3-30006-001_SDR RGB Red Green Blue (Camera Imagery) DP3-30010-001_RGB DEM Digital Surface and Terrain Models (DSM/DTM) DP3-30024-001_DEM CHM Canopy Height Model DP3-30015-001_CHM <p>The table below summarizes the sites, products, and years of NEON AOP data that can currently be accessed in GEE.</p> Domain Site Years Data Products D08 TALL 2017, 2018 SDR, RGB, CHM, DSM, DTM D11 CLBJ 2017, 2019 SDR, RGB, CHM, DSM, DTM D14 SRER 2017, 2018, 2019, 2021 SDR, RGB, CHM, DSM, DTM D16 WREF 2017, 2018 SDR, RGB, CHM, DSM, DTM D17 TEAK 2017, 2018 SDR, RGB, CHM, DSM, DTM"},{"location":"background/neon_aop_gee_data/#get-started-with-google-earth-engine","title":"Get Started with Google Earth Engine","text":"<p>Once you have set up your Google Earth Engine account you can navigate to the Earth Engine Code Editor. The diagram below, from the Earth-Engine Playground, shows the main components of the code editor. If you have used other programming languages such as R, Python, or Matlab, this should look fairly similar to other Integrated Development Environments (IDEs) you may have worked with. The main difference is that this has an interactive map at the bottom, similar to Google Maps and Google Earth. This editor is fairly intuitive. We encourage you to play around with the interactive map, or explore the ee documentation, linked above, to gain familiarity with the various features.</p>"},{"location":"background/neon_aop_gee_data/#read-aop-data-collections-into-gee","title":"Read AOP Data Collections into GEE","text":"<p>AOP data can be accessed through GEE through the <code>projects/neon</code> folder. In the remainder of this lesson, we will look at the three AOP datasets, or <code>ImageCollection</code>s in this folder.</p> <p>An ImageCollection is simply a group of images. To find publicly available datasets (primarily satellite data), you can explore the Earth Engine Data Catalog. Currently, NEON AOP data cannot be discovered in the main GEE data catalog, so the following steps will walk you through how to find available AOP data.</p> <p>In your code editor, copy and run the following lines of code to create 3 <code>ImageCollection</code> variables containing the Surface Directional Reflectance (SDR), Camera Imagery (RGB) and Digital Surface and Terrain Model (DEM) raster data sets.</p> <pre><code>//read in the AOP image collections as variables\n\nvar aopSDR = ee.ImageCollection('projects/neon/DP3-30006-001_SDR')\n\nvar aopRGB = ee.ImageCollection('projects/neon/DP3-30010-001_RGB')\n\nvar aopDEM = ee.ImageCollection('projects/neon/DP3-30024-001_DEM')\n</code></pre> <p>A few tips for the Code Editor: - In the left panel of the code editor, there is a Docs tab which includes API documentation on built in functions, showing the expected input arguments. We encourage you to refer to this documentation, as well as the  GEE JavaScript Tutorial to familiarize yourself with GEE and the JavaScript programming language. - If you have an error in your code, a red error message will show up in the Console (in the right panel), which tells you the line that failed. - Save your code frequently! If you try to leave your code while it is unsaved, you will be prompted that there are unsaved changes in the editor.</p> <p>When you Run the code above (by clicking on the Run above the code editor), you will notice that the lines of code become underlined in red, the same as you would see for a spelling error in most text editors. If you hover over each of the lines of codes, you will see a message pop up that says: <code>&lt;variable&gt; can be converted to an import record. Convert Ignore</code>.</p> <p>If you click <code>Convert</code>, the line of code will disappear and the variable will be imported into your session directly, and will show up at the top of the code editor. Go ahead and convert the variables for all three lines of code, so you should see the following. Tip: if you type Ctrl-z, you can re-generate the line of code, and the variable will still show up in the imported variables at the top of the editor. It is a good idea to retain the original code that reads in the variable, for reproducibility. If you don't do this, and wish to share this code with someone else, or run the code outside of your own code editor, the imported variables will not be saved.</p> <p>Note that each of these imported variables can now be expanded, using the arrow to the left of each. These variables now show associated information including type, id, and properties, which if you expand, shows a description. This provides more detailed information about the data product.</p> <p>Information about the image collections can also be found in a slightly more user-friendly format if you click on the blue <code>projects/neon/DP3-30006-001_SDR</code>, as well as <code>DP3-30010-001_RGB</code> and<code>DP3-30024-001_DEM</code>, respectively. Below we'll show the window that pops-up when you click on <code>SDR</code>, but we encourage you to look at all three datasets.</p> <p>This allows you to read the full description in a more user-friendly format. Note that the images imported into GEE may have some slight differences from the data downloaded from the data portal. For example, note that the reflectance data in GEE is scaled by 100. We highly encourage you to explore the description and associated documentation for the data products on the NEON data portal as well (eg. DP3.30006.001) for relevant information about the data products, how they are generated, and other pertinent details.</p> <p>You can also click on the <code>IMAGES</code> tab to explore all the available NEON images for that data product. Some of the text may be cut off in the default view, but if you click in one of the table values the table will expand. This table summarizes individual sites and years that are available for the SDR Image Collection. The ImageID provides the path to read in an individual image. In the next step, we will show how to use this path to pull in a single file.</p>"},{"location":"background/neon_aop_gee_data/#read-aop-data-into-gee-using-eeimage","title":"Read AOP Data into GEE using <code>ee.Image</code>","text":"<p>As a last step, we will go ahead and use the path specified in the SDR Asset Details Images table to read in a single image. Pulling in a single image uses almost identical syntax as an image collection, see below:</p> <pre><code>var TALL_2017_SDR = ee.Image('projects/neon/DP3-30006-001_SDR/DP3-30006-001_D08_TALL_SDR_2017')\n</code></pre> <p>Import this variable, and you can see that it pulls in to the Imports at the top, and shows <code>(426 bands)</code> at the right. To the right of that you will see blue eye and target icons. If you hover over the eye it displays \"Show on Map\". Click this eye icon to place a footprint of this data set in the Map display. If you hover over the target icon, you will see the option \"Center Map on Record\". Click this to center your map on this TALL SDR dataset. You should now see the footprint of the data as a layer in the Google Map.</p>"},{"location":"background/neon_aop_gee_data/#a-quick-recap","title":"A Quick Recap","text":"<p>You did it! You should now have a basic understanding of the GEE code editor and it's different components. You have also learned how to read a NEON AOP <code>ImageCollection</code> into a variable, import the variable into your code editor session, and navigate through the <code>ImageCollection</code> Asset details to find the path to an individual <code>Image</code>. Lastly, you learned to read in an individual SDR Image, pull the footprint of the data into a Map Layer, and center on that region.</p> <p>It doesn't look like we've done much so far, but this is a already great achievement! With just a few lines of code, you can import an entire AOP hyperspectral data set, which in most other coding environments, is not simple. One of the barriers to working with AOP data (and reflectance data in particular) is it's large data volume, which requires high-performance computing environments to carry out analysis. There are also limited open-source tools for working with the data; many of the software suites for working with hyperspectral data require licenses which can be expensive. In this lesson, we have loaded spectral data covering an entire site, and are ready for data exploration and analysis, in a free geospatial cloud-computing platform.</p> <p>In the next tutorials, we will pull in spectral data, visualize RGB and false color image composites, interactively plot spectral signatures of pixels in the image, and carry out some more advanced analysis that is highly simplified by the built in GEE functions.</p>"},{"location":"background/neon_aop_gee_data/#get-lesson-code","title":"Get Lesson Code","text":"<p>Into to AOP GEE Assets \u2192 \u2192</p>"},{"location":"background/neon_background/","title":"What is NEON?","text":"<p>NEON is a continental-scale observation facility designed to collect long-term open-access ecological data to better understand the complexities of Earth's ecosystems and how they are changing. NEON uses cutting-edge sensor networks, instrumentation, observational sampling, natural history archive facilities and remote sensing methods and technologies to collect data on plants, animals, soil, nutrients, freshwater and the atmosphere.</p> <p>NEON operates 81 field sites strategically located across 20 ecoclimatic Domains across the United States, including 47 terrestrial sites and 34 freshwater aquatic sites. When logistically possible, aquatic and terrestrial field sites are colocated (i.e. in close proximity) to support understanding of linkages across terrestrial and aquatic ecosystems and their interactions with the atmosphere. For example, Domain 08, the Ozarks Complex, has three co-located sets of terrestrial and aquatic field sites. These sites are situated along the same watershed system, creating a unique opportunity to study hydrology, nutrient transport, and biogeochemical cycling through the watershed.</p> <p> </p> NEON Field Sites Map - Green: Terrestrial Sites, Blue: Aquatic Sites <p>NEON delivers data products from three main sub-systems called the Airborne Observation Platform (AOP), Terrestrial and Aquatic Observational Systems (TOS/AOS), and the Instrumented Systems (TIS/AIS). The section below provides a brief summary of these sub-systems.</p>"},{"location":"background/neon_background/#neon-airborne-observation-platform-aop","title":"NEON Airborne Observation Platform (AOP)","text":"NEON Airborne Remote Sensing <p>Airborne remote sensing surveys are conducted over NEON field sites during peak greenness and provide quantitative information on land cover and changes to ecological structure and chemistry, including the presence and effects of invasive species. The surveys are supported by the NEON Airborne Observation Platform (AOP), a suite of earth observation instruments installed into a Twin Otter aircraft designed to collect high-resolution remote sensing data at low altitude. AOP was designed to collect regional-scale landscape information at the NEON field sites. The AOP maps areas where NEON's observational and instrumented sampling is occurring and allows relationships to be drawn between NEON's detailed in-situ observations to the broader environmental and ecological conditions.</p> <p>Learn More</p> <p>Please see the next section Airborne Observation Platform for more details on the AOP including a summary of the data products provided.</p>"},{"location":"background/neon_background/#neon-field-data","title":"NEON Field Data","text":"<p>In addition to the AOP remote sensing data, NEON also provides Observational Sampling (OS) data and Instrumented Sampling (IS) data at terrestrial and aquatic sites. The field and instrumented sampling are briefly described below, but we encourage exploring the NEON website further for a more detailed understanding of the sensors and data products provided by the OS and IS groups.</p>"},{"location":"background/neon_background/#observational-sampling","title":"Observational Sampling","text":"NEON Observational Samples <p>NEON field scientists collect a broad variety of observations and samples at terrestrial and aquatic field sites at regular intervals throughout the year. The data and samples collected by NEON's Aquatic Observation System (AOS) and Terrestrial Observation System (TOS) are designed to provide standardized, continentally distributed observations of organisms, biogeochemistry, and physical properties.</p>"},{"location":"background/neon_background/#instrumented-sampling","title":"Instrumented Sampling","text":"NEON Instrumented Sampling <p>NEON deploys automated instruments to collect meteorological, soil, phenological, surface water, and groundwater data at NEON field sites.</p> <p>Colocated Sites</p> <p>Where logistically possible, NEON colocated aquatic sites with terrestrial sites (21 in total) to support an understanding of linkages across atmospheric, terrestrial, and aquatic ecosystems. The suite of OS, IS, and AOP data provide an unparalleled opportunity to study ecosystem-level change over time in the United States.</p>"},{"location":"gee/gee_catalog/","title":"Earth Engine Data Catalog 90+ Petabytes of Geospatial Data","text":"<p>Catalog Overview</p> <p>1000+ datasets \u2022 90+ petabytes of data \u2022 Continuously updated \u2022 Free access to most datasets</p> <p>The Earth Engine data catalog represents one of the world's largest collections of publicly available geospatial datasets. Originally designed around primary datasets curated by the Earth Engine team, the catalog has grown into a comprehensive repository that democratizes access to satellite imagery, climate data, and geophysical datasets from around the globe.</p> <p> </p> Exploring the Earth Engine Data Catalog interface"},{"location":"gee/gee_catalog/#dataset-categories","title":"Dataset Categories","text":"<p>The catalog spans multiple domains of Earth observation and environmental monitoring:</p> Satellite ImageryClimate &amp; WeatherTerrain &amp; TopographyEnvironmental <ul> <li>Landsat Collection - 50+ years of Earth observation</li> <li>Sentinel Series - High-resolution European Space Agency data</li> <li>MODIS - Daily global coverage for environmental monitoring</li> <li>Planet - High-frequency, high-resolution commercial imagery</li> </ul> <ul> <li>ERA5 Reanalysis - Comprehensive atmospheric data</li> <li>CHIRPS - Precipitation datasets for climate monitoring</li> <li>Temperature Records - Historical and real-time temperature data</li> <li>Weather Station Data - Ground-based meteorological observations</li> </ul> <ul> <li>SRTM - Global digital elevation models</li> <li>ASTER GDEM - High-resolution terrain data</li> <li>Global Forest Change - Annual forest loss and gain</li> <li>Land Cover Classifications - Multiple global and regional products</li> </ul> <ul> <li>Air Quality - Pollution and atmospheric composition</li> <li>Ocean Data - Sea surface temperature, salinity, currents</li> <li>Biodiversity - Species distribution and habitat data</li> <li>Urban Development - Built environment and infrastructure</li> </ul>"},{"location":"gee/gee_catalog/#finding-your-data","title":"Finding Your Data","text":""},{"location":"gee/gee_catalog/#quick-search-methods","title":"Quick Search Methods","text":"<p>Search Strategies</p> <p>\ud83d\udd0d By Keywords: Use terms like \"landsat\", \"temperature\", \"precipitation\"</p> <p>\ud83d\uddd3\ufe0f By Date Range: Filter datasets by temporal coverage</p> <p>\ud83c\udf0d By Geographic Area: Search for region-specific datasets</p> <p>\ud83d\udcca By Data Type: Filter by imagery, tables, or image collections</p> <p> </p> Searching for datasets directly in the Earth Engine Code Editor"},{"location":"gee/gee_catalog/#access-points","title":"Access Points","text":"<p>Where to Find Data</p> <p>\ud83c\udf10 Main Catalog Browser - Web-based dataset explorer</p> <p>\ud83d\udccb Complete Dataset List - All available datasets in one view</p> <p>\ud83d\udcbb Code Editor Search - Built-in search within the development environment</p> <p>\ud83d\udcd6 Dataset Tags - Browse by thematic categories</p>"},{"location":"gee/gee_catalog/#specialized-collections","title":"Specialized Collections","text":"<p>Domain-Specific Highlights</p> <p>\ud83c\udf31 Agriculture: Crop type maps, NDVI time series, soil moisture</p> <p>\ud83c\udfd9\ufe0f Urban Planning: Nighttime lights, population density, built-up areas</p> <p>\ud83c\udf0a Water Resources: Surface water occurrence, flood mapping, water quality</p> <p>\ud83d\udd25 Disaster Response: Fire detection, damage assessment, emergency mapping</p>"},{"location":"gee/gee_catalog/#data-licensing-and-usage","title":"Data Licensing and Usage","text":""},{"location":"gee/gee_catalog/#understanding-access-rights","title":"Understanding Access Rights","text":"<p>Important Licensing Information</p> <ul> <li>Most datasets are free for research and non-commercial use</li> <li>Commercial datasets require specific licensing (clearly marked)</li> <li>Citation requirements vary by dataset - check individual dataset pages</li> <li>Usage limits may apply to some high-resolution commercial data</li> </ul>"},{"location":"gee/gee_catalog/#best-practices","title":"Best Practices","text":"Before Using DataFor Reproducible Research <ol> <li>Read the dataset description thoroughly</li> <li>Check temporal and spatial coverage for your area of interest</li> <li>Review licensing terms and citation requirements</li> <li>Understand data quality and known limitations</li> </ol> <ol> <li>Document dataset versions and access dates</li> <li>Include proper citations in publications</li> <li>Note any preprocessing applied to the data</li> <li>Share your analysis code when possible</li> </ol>"},{"location":"gee/gee_catalog/#advanced-catalog-features","title":"Advanced Catalog Features","text":""},{"location":"gee/gee_catalog/#programmatic-access","title":"Programmatic Access","text":"<p>For power users and automated workflows, the catalog can be accessed programmatically:</p> <ul> <li>Earth Engine API - Direct dataset access through code</li> <li>Asset Management - Import and manage your own datasets</li> <li>Shared Assets - Access community-contributed datasets</li> <li>Apps Integration - Use catalog data in Earth Engine Apps</li> </ul>"},{"location":"gee/gee_community_catalog/","title":"Awesome GEE Community Catalog Community-Driven Geospatial Datasets","text":"<p>Community-Powered Data Commons</p> <p>Community-sourced datasets \u2022 Open licenses \u2022 Ready-to-use Earth Engine assets \u2022 Preprocessed for immediate analysis</p> <p>The Awesome GEE Community Catalog represents a grassroots effort to democratize access to geospatial data. This community-driven repository addresses a critical gap: research datasets that often require extensive preprocessing before they can be used in Google Earth Engine. By providing ready-to-use Earth Engine assets, the catalog eliminates barriers and accelerates research workflows.</p> <p> </p> Awesome GEE Community Catalog - Bridging data gaps through community collaboration <p>Project Origins</p> <p>\ud83d\udcd6 Learn More: Community Datasets: Data Commons in Google Earth Engine</p> <p>The project emerged from the recognition that many valuable research datasets remained inaccessible due to preprocessing complexity, licensing confusion, or format incompatibilities.</p>"},{"location":"gee/gee_community_catalog/#why-community-catalog-matters","title":"Why Community Catalog Matters","text":""},{"location":"gee/gee_community_catalog/#addressing-real-challenges","title":"Addressing Real Challenges","text":"Data AccessibilityOpen ScienceResearch Acceleration <ul> <li>Preprocessing Barriers - Complex datasets made analysis-ready</li> <li>Format Standardization - Consistent Earth Engine asset formats</li> <li>Documentation - Clear metadata and usage examples</li> <li>Quality Assurance - Community-validated datasets</li> </ul> <ul> <li>Open Licenses - Transparent usage rights</li> <li>Reproducible Research - Standardized data access</li> <li>Community Validation - Peer-reviewed quality</li> <li>Knowledge Sharing - Collaborative improvement</li> </ul> <ul> <li>Immediate Access - Skip time-consuming preprocessing</li> <li>Tested Examples - Working code for quick starts</li> <li>Domain Organization - Intuitive dataset discovery</li> <li>Regular Updates - Community-maintained freshness</li> </ul>"},{"location":"gee/gee_community_catalog/#dataset-categories","title":"Dataset Categories","text":"<p>The catalog organizes datasets into thematic domains for intuitive discovery:</p>"},{"location":"gee/gee_community_catalog/#core-domains","title":"Core Domains","text":"Domain Focus Areas Example Datasets \ud83c\udfd9\ufe0f Population &amp; Socioeconomics Demographics, economic indicators, urban development Population grids, poverty maps, economic activity \ud83c\udf31 Agriculture &amp; Food Security Crop mapping, yield prediction, food systems Crop type maps, agricultural statistics, food prices \ud83c\udf0a Hydrology &amp; Water Resources Water availability, quality, infrastructure River networks, water bodies, groundwater data \ud83d\udd25 Disasters &amp; Hazards Risk assessment, emergency response Flood maps, fire perimeters, vulnerability indices \ud83c\udf3f Ecology &amp; Biodiversity Species distribution, habitat mapping Protected areas, species occurrence, ecosystem maps \ud83c\udfd7\ufe0f Infrastructure &amp; Transportation Built environment, connectivity Road networks, building footprints, facility locations"},{"location":"gee/gee_community_catalog/#specialized-collections","title":"Specialized Collections","text":"<p>Unique Dataset Highlights</p> <p>\ud83d\udef0\ufe0f Radar &amp; SAR Data - Preprocessed radar datasets for advanced analysis</p> <p>\ud83d\udcca Statistical Surfaces - Gridded statistical data from national surveys</p> <p>\ud83d\uddfa\ufe0f Administrative Boundaries - High-quality boundary datasets for multiple countries</p> <p>\u23f0 Historical Archives - Digitized historical maps and imagery</p>"},{"location":"gee/gee_community_catalog/#navigating-the-catalog","title":"Navigating the Catalog","text":""},{"location":"gee/gee_community_catalog/#discovery-methods","title":"Discovery Methods","text":"Exploring datasets by thematic domains - expand categories to discover relevant datasets <p>Finding the Right Dataset</p> <p>\ud83d\udcc2 Browse by Domain - Expand thematic categories to explore related datasets</p> <p>\ud83d\udd0d Keyword Search - Use the search bar for specific terms, tags, or dataset names</p> <p>\ud83c\udff7\ufe0f Tag Filtering - Combine multiple tags to narrow your search</p> <p>\ud83d\udccb Asset Lists - Each dataset page shows all available Earth Engine assets</p> <p> </p> Using the search functionality to quickly find datasets by name, keywords, or tags"},{"location":"gee/gee_community_catalog/#dataset-pages","title":"Dataset Pages","text":"<p>Each dataset in the catalog provides comprehensive information:</p> Essential InformationTechnical DetailsUsage Resources <ul> <li>Dataset Description - Comprehensive overview and methodology</li> <li>Spatial/Temporal Coverage - Geographic extent and time range</li> <li>Data Source - Original data providers and processing details</li> <li>Licensing Information - Clear usage rights and restrictions</li> </ul> <ul> <li>Earth Engine Asset IDs - Direct links to data assets</li> <li>Coordinate Reference System - Projection and datum information</li> <li>Resolution Specifications - Spatial and temporal resolution</li> <li>Data Quality Notes - Known limitations and considerations</li> </ul> <ul> <li>Example Code - Working JavaScript and Python examples</li> <li>Visualization Parameters - Pre-configured display settings</li> <li>Processing Tips - Best practices for analysis</li> <li>Citation Guidelines - Proper attribution requirements</li> </ul>"},{"location":"gee/gee_community_catalog/#integration-with-earth-engine","title":"Integration with Earth Engine","text":""},{"location":"gee/gee_community_catalog/#code-editor-repository","title":"Code Editor Repository","text":"Adding the community catalog repository to your Earth Engine Code Editor for easy access <p>Easy Integration</p> <p>\ud83d\udd17 Add Repository: Include the entire catalog as a Code Editor repository</p> <p>\ud83d\udcf1 Quick Access: Browse examples directly in your development environment</p> <p>\ud83d\udd04 Automatic Updates: Stay current with new datasets and improved examples</p> <p>\ud83d\udcbb Ready-to-Run Code: Copy and modify examples for your specific needs</p>"},{"location":"gee/gee_community_catalog/#working-with-community-datasets","title":"Working with Community Datasets","text":"<pre><code>// Example: Loading a community dataset\nvar populationGrid = ee.Image('projects/sat-io/open-datasets/worldpop/ppp_2020_1km_Aggregated');\n\n// Apply filtering and visualization\nvar visualization = {\n  min: 0,\n  max: 1000,\n  palette: ['white', 'yellow', 'orange', 'red', 'purple']\n};\n\nMap.addLayer(populationGrid, visualization, 'Population Density 2020');\n</code></pre> <p>Best Practices for Community Data</p> <p>\u26a1 Check Asset Status - Verify asset availability before deployment</p> <p>\ud83d\udcd6 Read Documentation - Understand processing methodology and limitations</p> <p>\ud83c\udff7\ufe0f Use Proper Citations - Credit original data providers and catalog contributors</p> <p>\ud83d\udd04 Stay Updated - Monitor for dataset updates and improvements</p>"},{"location":"gee/gee_community_catalog/#contributing-to-the-catalog","title":"Contributing to the Catalog","text":""},{"location":"gee/gee_community_catalog/#how-to-get-involved","title":"How to Get Involved","text":"<p>Community Participation</p> <p>The catalog thrives on community contributions. Here's how you can help:</p> Data ContributorsTechnical ContributorsCommunity Support <ul> <li>Submit Datasets - Share your preprocessed research datasets</li> <li>Improve Documentation - Enhance existing dataset descriptions</li> <li>Validate Quality - Test and verify dataset accuracy</li> <li>Update Examples - Improve or add new code examples</li> </ul> <ul> <li>Code Development - Enhance catalog infrastructure</li> <li>Bug Reporting - Identify and report issues</li> <li>Feature Requests - Suggest new functionality</li> <li>Testing - Validate new features and datasets</li> </ul> <ul> <li>User Feedback - Share experiences and suggestions</li> <li>Documentation - Improve tutorials and guides</li> <li>Outreach - Promote catalog usage in your networks</li> <li>Training - Help others learn to use community datasets</li> </ul>"},{"location":"gee/gee_community_catalog/#contribution-guidelines","title":"Contribution Guidelines","text":"<p>Quality Standards</p> <p>\ud83d\udccb Documentation Required - Complete metadata and usage examples</p> <p>\u2696\ufe0f Open Licensing - Datasets must use open, clearly specified licenses</p> <p>\ud83d\udd0d Quality Assurance - Data must be validated and tested</p> <p>\ud83e\udd1d Community Review - Submissions undergo peer review process</p>"},{"location":"gee/gee_community_catalog/#impact-and-recognition","title":"Impact and Recognition","text":""},{"location":"gee/gee_community_catalog/#growing-ecosystem","title":"Growing Ecosystem","text":"<p>The Awesome GEE Community Catalog has become an essential resource for the Earth Engine community:</p> <ul> <li>\ud83c\udf0d Global Reach - Used by researchers and practitioners worldwide</li> <li>\ud83d\udcc8 Growing Collection - Continuously expanding dataset portfolio</li> <li>\ud83c\udf93 Educational Value - Supporting teaching and learning initiatives</li> <li>\ud83d\udd2c Research Enablement - Accelerating scientific discoveries</li> </ul>"},{"location":"gee/gee_community_catalog/#academic-citation","title":"Academic Citation","text":"<p>When using datasets from the community catalog, please cite both the original data source and the catalog project:</p> <p>Citation Format</p> <p>Roy, S., &amp; Swetnam, T. (2024). samapriya/awesome-gee-community-datasets: Community Catalog (2.6.0). Zenodo. https://doi.org/10.5281/zenodo.11118613</p>"},{"location":"gee/gee_community_catalog/#getting-started","title":"Getting Started","text":""},{"location":"gee/gee_community_catalog/#quick-start-guide","title":"Quick Start Guide","text":"<ol> <li>\ud83c\udf10 Explore the Catalog - Visit gee-community-catalog.org</li> <li>\ud83d\udd0d Find Your Data - Use search or browse by domain</li> <li>\ud83d\udcd6 Read Documentation - Understand dataset specifications and limitations</li> <li>\ud83d\udcbb Try Examples - Run provided code in Earth Engine Code Editor</li> <li>\ud83d\ude80 Build Your Analysis - Adapt examples for your research needs</li> </ol>"},{"location":"gee/gee_community_catalog/#next-steps","title":"Next Steps","text":"<p>Maximize Your Impact</p> <p>\ud83e\udd1d Join the Community - Engage with other users and contributors</p> <p>\ud83d\udce2 Share Your Work - Showcase analyses built with community datasets</p> <p>\ud83d\udd04 Give Feedback - Help improve datasets and documentation</p> <p>\ud83d\udcda Stay Informed - Follow updates and new dataset announcements</p> <p>The Awesome GEE Community Catalog represents the power of collaborative science - join the community and help democratize access to geospatial data.</p>"},{"location":"gee/gee_overview/","title":"Google Earth Engine Browser Based Remote Sensing","text":"<p>Key Benefits</p> <p>90+ petabytes of open geospatial data \u2022 Cloud-based processing \u2022 JavaScript &amp; Python SDKs \u2022 Scalable analysis from local to global</p> <p>Google Earth Engine brings the power of remote sensing analysis into the browser. With just an internet connection, anyone can tap into this cloud-based platform to process and query massive geospatial datasets.</p> <p>Earth Engine levels the playing field for working with satellite imagery and raster data at scale. It hosts one of the largest repositories of open geospatial assets (over 90+ petabytes), while ingesting new data continuously. Users can perform analysis across these indexed layers, going from local to global, using JavaScript and Python SDKs. The cloud infrastructure allows researchers to iterate rapidly and run computations on petabytes of data. Results are shareable, published outputs that ensure reproducibility. Earth Engine simplifies the process from data access to analysis to dissemination.</p> <p> </p> What is Google Earth Engine <p>Why Earth Engine Matters</p> <p>By moving most of the processing into the cloud, Earth Engine makes remote sensing more accessible. Users now wield these capabilities through any web browser. This democratization of geospatial analytics opens up new possibilities for applications across numerous domains.</p>"},{"location":"gee/gee_overview/#capabilities-and-limitations","title":"Capabilities and Limitations","text":"<p>Understanding what Google Earth Engine excels at\u2014and where it has boundaries\u2014helps you make the most of this powerful platform.</p>"},{"location":"gee/gee_overview/#what-earth-engine-does-best","title":"What Earth Engine Does Best","text":"Image ProcessingVector ProcessingTerrain AnalysisTime SeriesAdvanced Analytics <ul> <li>Map Algebra, Kernels and Convolutions</li> <li>Spectral Unmixing, Pan-sharpening</li> <li>Gap Filling, Data Fusion</li> </ul> <ul> <li>Zonal Statistics, Spatial Joins</li> <li>Spatial Query operations</li> </ul> <ul> <li>Slope, Aspect, Hillshades</li> <li>Hill Shadow Analysis</li> </ul> <ul> <li>Extract Time-Series, Trend Analysis</li> <li>Time-Series Smoothing</li> <li>Temporal Segmentation</li> </ul> <ul> <li>Object-based Image Analysis (GLCM, Texture, Hotspots)</li> <li>Change Detection (Spectral Distance, Change Classification)</li> <li>Machine Learning (Supervised/Unsupervised Classification, PCA)</li> <li>Deep Learning (DNN, Object Detection via TensorFlow)</li> </ul>"},{"location":"gee/gee_overview/#current-limitations","title":"Current Limitations","text":"<p>Not supported in Earth Engine</p> <ul> <li>Cartographic Outputs - No traditional map layout tools</li> <li>3D Visualization - Limited to 2D analysis and display</li> <li>Hydrological Modeling - No rainfall-runoff or watershed tools</li> <li>Photogrammetry - No orthorectification or point cloud processing</li> <li>LiDAR Processing - No specialized LiDAR analysis tools</li> <li>SAR Interferometry - Limited SAR analysis capabilities</li> </ul>"},{"location":"gee/gee_overview/#additional-resources","title":"Additional Resources","text":"<p>Learn More</p> <p>\ud83d\udcc4 Research Paper: Google Earth Engine: Planetary-scale geospatial analysis for everyone</p> <p>\ud83d\udcda Comprehensive Guide: Cloud-Based Remote Sensing with Google Earth Engine: Fundamentals and Applications - Open source book by the GEE community</p> <p> </p> Snippet from the Google Earth Engine main paper. Source"},{"location":"setup/getting_started/","title":"Getting Started","text":"<p>This guide will help you prepare for the workshop by setting up your Google Earth Engine account and understanding the prerequisites.</p>"},{"location":"setup/getting_started/#prerequisites","title":"Prerequisites","text":"<p>Participants should have basic familiarity with Google Earth Engine and experience coding in a scientific language (e.g., Python, R, JavaScript) is recommended. Participants must sign up for a Google Earth Engine account and set up a cloud project to follow along with the live-coding exercises.</p>"},{"location":"setup/getting_started/#setup-instructions","title":"Setup Instructions","text":"<p>To follow along during the workshop, or to run through the tutorials contained within the repository using the Google Earth Engine Code Editor, the following steps are required.</p>"},{"location":"setup/getting_started/#1-google-earth-engine-account","title":"1. Google Earth Engine Account","text":"<p>Create a Noncommercial Google Earth Engine account (if you don't already have one) at https://earthengine.google.com/noncommercial/</p>"},{"location":"setup/getting_started/#2-google-earth-engine-project","title":"2. Google Earth Engine Project","text":"<p>Once your EE account is set up, you will need to create a Google Cloud project. This is required to run the live-coding exercises. You can follow the instructions in the Google Earth Engine access guide to set up your project.</p>"},{"location":"setup/getting_started/#3-hardware-requirements","title":"3. Hardware Requirements","text":"<p>Following along with the exercises requires a laptop or tablet with a stable internet connection.</p>"},{"location":"setup/getting_started/#next-steps","title":"Next Steps","text":"<p>Once you've completed the setup above, you'll be ready to participate in the workshop exercises. Make sure to test your Google Earth Engine access by logging into the Earth Engine Code Editor before the workshop begins.</p> <p>If you encounter any issues during setup, please reach out to the workshop organizers for assistance.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/","title":"Introduction to AOP Public Datasets in Google Earth Engine (GEE)","text":"\ud83d\udccb Tutorial Details\ud83c\udff7\ufe0f Topics &amp; Data <ul> <li>Duration: 30 minutes</li> <li>Level: Intermediate</li> <li>Authors: Bridget Hass, John Musinsky</li> <li>Contributors: Tristan Goulden, Lukas Straube</li> </ul> <ul> <li>Topics: lidar, hyperspectral, camera, remote-sensing</li> <li>Data Products: DP3.30006.001, DP3.30006.002, DP3.30010.001, DP3.30015.001, DP3.30024.001</li> </ul>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#neon-aop-data-in-google-earth-engine","title":"NEON AOP Data in Google Earth Engine","text":"<p>Google Earth Engine (GEE) is a free and powerful cloud-computing platform for carrying out remote sensing and geospatial data analysis. In this tutorial, we introduce you to the NEON AOP datasets that have been added to Google Earth Engine as Publisher Datasets.</p> <p></p> <p>NEON is planning to add the full archive of AOP L3 Surface Bidirectional Reflectance, LiDAR Elevation, Ecosystem Structure, and High-resolution orthorectified camera imagery. Since the L3 Surface Directional Reflectance is being replaced by the bidirectional (Bidirectional Reflectance Distribution Function (BRDF) and topographic corrected) reflectance as that becomes available, we are only adding directional reflectance data to GEE upon request.</p> <p>Data Availability Update</p> <p>As of July 2025, bidirectional data is only available for AOP data collected between 2022-2024, but re-processing of older AOP data (2013-2021) will begin in mid-2025. Please see the tutorial Introduction to Bidirectional Hyperspectral Reflectance Data in Python for more information on the differences between the directional and bidirectional reflectance data products.</p> <p>It will take time for the full archive of AOP data to be added to GEE, but NEON has been ramping up data additions starting in Fall 2024. This tutorial shows you how to find which data are currently available. If there are certain NEON sites and years of data you would like to see added to Google Earth Engine sooner, use the NEON Contact Us form to request this, and include \"Google Earth Engine Remote Sensing Data\" in the text.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#objectives","title":"Objectives","text":"<p>After completing this activity, you will become familiar with:</p> <ul> <li>Google Earth Engine (GEE)</li> <li>NEON AOP Image Collections in GEE</li> </ul> <p>And you will be able to:</p> <ul> <li>Write and run basic JavaScript code in the GEE Code Editor</li> <li>Discover which NEON AOP datasets are available in GEE</li> <li>Explore the NEON AOP GEE Image Collections</li> <li>Plot an RGB image of a reflectance dataset</li> <li>Compare bidirectional and directional reflectance datasets</li> </ul>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#requirements","title":"Requirements","text":"<ul> <li>A Google or gmail (@gmail.com) account</li> <li>An Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/. Click on \"Register a Noncommercial or Commercial Cloud Project\", and on the next prompt select \"Unpaid Usage\" and select the Project Type to create a free non-commercial account. For more information, refer to Noncommercial Earth Engine</li> <li>A Google Cloud Project. See Set up your Earth Engine enabled Cloud Project</li> <li>A basic understanding of the GEE Code Editor and the GEE JavaScript API</li> </ul>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#additional-resources","title":"Additional Resources","text":"<p>If this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start.</p> <ul> <li>Get Started with Earth-Engine</li> <li>GEE JavaScript Tutorial</li> </ul>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#aop-gee-data-access","title":"AOP GEE Data Access","text":"<p>AOP has currently added a subset of AOP Level 3 (tiled) data products at over 50 NEON sites spanning 10 years on GEE (as of Jan 2025). The NEON data products that have been made available on GEE can be currently be found on the GEE Datasets page, if you search for \"NEON\" as follows:</p> <p></p> <p>In the code editor, NEON datasets can be accessed through the <code>projects/neon-prod-earthengine</code> folder with an appended suffix of the Acronym and Revision Number, shown in the table below. For example, the Surface Directional Reflectance can be found under the path <code>projects/neon-prod-earthengine/assets/HSI_REFL/001</code>. The table below summarizes the GEE and NEON Data Portal IDs for each data product, and can be used as a reference for reading in AOP GEE datasets.</p> GEE Acronym/Revision Data Product Name Data Product ID HSI_REFL/001 Surface Directional Reflectance DP3.30006.001 HSI_REFL/002 Surface Bidirectional Reflectance DP3.30006.002 RGB/001 Red Green Blue (Camera Imagery) DP3.30010.001 DEM/001 Digital Elevation Model (DSM/DTM) DP3.30024.001 CHM/001 Ecosystem Structure (Canopy Height Model; CHM) DP3.30015.001"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#get-started-with-google-earth-engine","title":"Get Started with Google Earth Engine","text":"<p>Once you have set up your Google Earth Engine account you can navigate to the Earth Engine Code Editor. The diagram below, from the Earth-Engine Playground, shows the main components of the code editor. If you have used other programming languages such as R, Python, or Matlab, this should look fairly similar to other Integrated Development Environments (IDEs) you may have worked with. The main difference is that this has an interactive map at the bottom, similar to Google Maps and Google Earth.</p> <p></p> <p>We encourage you to play around with the interactive map, or explore the ee documentation, linked above, to gain familiarity with the various features.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#read-aop-data-collections-into-gee","title":"Read AOP Data Collections into GEE","text":"<p>AOP data can currently be accessed through GEE through the <code>projects/neon-prod-earthengine/assets/</code> folder. In the remainder of this lesson, we will look at the five available AOP datasets, or <code>ImageCollections</code>.</p> <p>An ImageCollection is simply a group of images. To find publicly available datasets (primarily satellite data), you can explore the Earth Engine Data Catalog. The following steps will walk you through how to read in AOP Image Collections in the Code Editor.</p> <p>In your code editor, copy and run the following lines of code to create 5 <code>ImageCollection</code> variables containing the Surface Directional Reflectance (HSI_REFL/001), Surface Bidirectional Reflectance (HSI_REFL/002), Camera Imagery (RGB), Canopy Height Model (CHM), and Digital Elevation Model (DEM) raster data sets.</p> <pre><code>//read in the AOP image collections as variables\n\nvar refl001 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/001')\n\nvar refl002 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/002')\n\nvar rgb = ee.ImageCollection('projects/neon-prod-earthengine/assets/RGB/001')\n\nvar chm = ee.ImageCollection('projects/neon-prod-earthengine/assets/CHM/001')\n\nvar dem = ee.ImageCollection('projects/neon-prod-earthengine/assets/DEM/001')\n</code></pre> <p>Working in the Code Editor</p> <ul> <li>In the left panel of the code editor, there is a Docs tab which includes API documentation on built in functions, showing the expected input arguments. We encourage you to refer to this documentation, as well as the GEE JavaScript Tutorial to familiarize yourself with GEE and the JavaScript programming language.</li> <li>If you have an error in your code, a red error message will show up in the Console (in the right panel), which tells you the line that failed.</li> <li>Save your code frequently! If you try to leave your code while it is unsaved, you will be prompted that there are unsaved changes in the editor.</li> </ul> <p>When you Run the code above (by clicking on the Run above the code editor), you will notice that the lines of code become underlined in red, the same as you would see for a spelling error in most text editors. If you hover over each of the lines of codes, you will see a message pop up that prompts you to Convert the variable into an import record.</p> <p></p> <p>If you click <code>Convert</code>, the line of code will disappear and the variable will be imported into your session directly, and will show up at the top of the code editor. Go ahead and convert the variables for all three lines of code, so you should see the following.</p> <p>Maintaining Reproducibility</p> <p>If you type <code>Ctrl-z</code>, you can re-generate the line of code, and the variable will still show up in the imported variables at the top of the editor. It is recommended to retain the code that reads in each variable, for reproducibility. If you don't do this, and wish to share this code with someone else, or run the code outside of your current code editor, the imported variables will not be saved and any subsequent code referring to this variable will result in an error message.</p> <p></p> <p>Note that each of these imported variables can now be expanded, using the arrow to the left of each. These variables now show associated information including type, id, and version.</p> <p>Information about the image collections can also be found in a slightly more user-friendly format if you click on the blue link, eg. <code>projects/neon-prod-earthengine/CHM/001</code>. Below we'll show the window that pops-up when you click on the CHM link. We encourage you to explore all of the AOP datasets similarly.</p> <p></p> <p>Dataset Information</p> <p>You can also search for the NEON AOP image collections through the search bar on the Earth Engine Data Catalog webpage. The dataset page also contains all the information about the data product, eg. NEON Canopy Height Model (CHM).</p> <p>The end of the description includes a link to the Data Product landing page on the NEON Data Portal, as well as the Quick Start Guide, which includes links to all the documentation pertaining to this NEON data product, including the Algorithm Theoretical Basis Documents (ATBDs). Click on the other tabs to explore more about this data product. These tabs include <code>DESCRIPTION</code>, <code>BANDS</code>, <code>IMAGE PROPERTIES</code>, <code>TERMS OF USE</code>, AND <code>CITATIONS</code>.</p> <p>Alternative Search Method</p> <p>You can also search for NEON data products through Code Editor by typing \"NEON\" in the search bar as shown below:</p> <p></p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#aop-gee-data-availability","title":"AOP GEE Data Availability","text":"<p>Since we are adding AOP data to GEE on a rolling basis, the first thing you may want to do after reading in the image collections is to determine which datasets are currently available on GEE. A quick way to do this is shown below:</p> <pre><code>// list all available images in the NEON Surface Directional Reflectance Image Collection:\nprint('NEON Images in the Directional Reflectance Collection',\n      refl001.aggregate_array('system:index'))\n\n// list all available images in the NEON Surface Bidirectional Reflectance Image Collection:\nprint('NEON Images in the Bidirectional Reflectance Collection',\n      refl002.aggregate_array('system:index'))\n\n// list all available images in the NEON DEM image collection:\nprint('NEON Images in the DEM Collection',\n      dem.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the CHM Collection',\n      chm.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the RGB Camera Collection',\n      rgb.aggregate_array('system:index'))\n</code></pre> <p>In the Console tab to the right of the code, you will see a list of all available images. Expand each List to see the data available for each Image Collection. The names of the all the images follow the format <code>YEAR_SITE_#</code>, so you can identify the site and year of data this way. The number at the end is the Visit #; AOP typically visits each site 3 out of every 5 years, so the visit number indicates the cumulative number of times AOP has visited that site. Occasionally, AOP may re-visit a site twice in the same year.</p> <p></p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#filter-by-image-properties","title":"Filter by Image Properties","text":"<p>Next, we can explore some filtering options to pull out individual images from an Image Collection. In the example shown below, we can filter by the date (<code>.filterDate</code>) by providing a date range, and filter by other properties, such as the NEON site code, using <code>.filterMetadata</code>. For this example we'll pull in an image from the NEON site Lyndon B. Johnson National Grassland NEON (CLBJ).</p> <pre><code>// read in a single reflectance image at the NEON site CLBJ in 2021\nvar refl001_CLBJ_2021 = refl001\n  .filterDate('2021-01-01', '2021-12-31') // filter by date - 2021\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image\n</code></pre>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#explore-image-properties","title":"Explore Image Properties","text":"<p>Next let's take a look at the Image Properties.</p> <pre><code>// look at the image properties\nvar clbj2021_refl_properties = refl001_CLBJ_2021.toDictionary()\nprint('CLBJ 2021 Directional Reflectance Properties:', clbj2021_refl_properties)\n</code></pre> <p>Look in the Console for the properties, you can expand by clicking on the arrow to the left of the <code>Object (438 properties)</code>. Here you can see some metadata about this image. Scroll down and you'll get to a number of properties starting with <code>WL_FWHM_B###</code>. These are the WaveLength (WL) and Full Width Half Max (FWHM) values, in nanometers, corresponding to each band (Bands 001 - 426). You may wish to refer to this wavelength information to determine which bands you wish to display, eg. if you want to show a false color image instead of a true color (RGB) image. For a full description of what each of the Image Properties mean, you can look at the <code>IMAGE PROPERTIES</code> tab as explained in the previous section, or find it in the Earth Engine Data Catalog.</p> <p></p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#determine-release-tag-information","title":"Determine Release Tag Information","text":"<p>When working with NEON data, whether downloaded from the Data Portal or on GEE, we always recommend checking whether the data are Provisional or Released, and the release tag of the data. On GEE, this information is included in the image properties <code>PROVISIONAL_RELEASED</code> and <code>RELEASE_YEAR</code>. If the data is released, the property <code>RELEASE_YEAR</code> will display the year of the release. The code chunk below shows how to display the release information for the CLBJ 2021 directional reflectance data.</p> <pre><code>// determine the release information for this image\nvar clbj2021_release_status = clbj2021_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2021 Directional Reflectance Release Status:', clbj2021_release_status)\n\nvar clbj2021_release_year = clbj2021_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2021 Directional Reflectance Release Year:', clbj2021_release_year)\n</code></pre> <p>In this example, the data is part of <code>RELEASE-2024</code>.</p> <p>NEON Data Releases</p> <p>For more information on NEON releases, refer to the NEON Data Product Revisions and Releases page. There is a short period each year in January where AOP data on the NEON Data Portal may be in flux in preparation for an upcoming data release (typically end of January). GEE datasets are planned to be kept up to date with the current release, however there may be a lag period between the annual release and data updates on GEE. Data on GEE should be updated to match the current release by the end of February each year. For current information around the release status and data quality issue notices, you can follow NEON Data Notifications.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#plot-a-true-color-image","title":"Plot a True Color Image","text":"<p>Finally, let's plot a true color image (red-green-blue or RGB composite) of the reflectance data that we've read into the variable <code>refl001_CBLJ_2021</code>. To do this, first we pull out the RGB bands, set visualization parameters, center the map over the site, and then add the map using <code>Map.addLayer</code>. There are a couple ways you can center the Map to the location you want. One is to use <code>Map.centerObject</code> and you can provide the image you want to center; otherwise you can specify the latitude and longitude, shown commented-out in the code chunk below.</p> <pre><code>// pull out the red, green, and blue bands\nvar refl001_CLBJ_2021_RGB = refl001_CLBJ_2021.select(['B053', 'B035', 'B019']);\n\n// set visualization parameters\nvar refl_rgb_vis = {min: 0, max: 1260, gamma: 0.8};\n\n// use centerObject to center on the reflectance data, 13 is the zoom level\nMap.centerObject(refl001_CLBJ_2021, 13)\n\n// alternatively you could specify the lat / lon of the site, set zoom to 13\n// you can find the field site lat/lon here https://www.neonscience.org/field-sites/clbj\n// Map.setCenter(-97.57, 33.40, 13);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl001_CLBJ_2021_RGB, refl_rgb_vis, 'CLBJ 2021 Directional Reflectance RGB');\n</code></pre> <p>When you run the code you should now see the true color image on the map! You can zoom in and out and explore some of the other interactive options on your own.</p> <p></p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#compare-directional-and-bidirectional-reflectance","title":"Compare Directional and Bidirectional Reflectance","text":"<p>Lastly, let's also look at a bidirectional data product at the same site, and you can explore the differences between the directional and bidirectional reflectance. We will also display the release information for this data.</p> <pre><code>// read in a bidirectional reflectance image at the NEON site CLBJ in 2022\nvar refl002_CLBJ_2022 = refl002\n  .filterDate('2022-01-01', '2022-12-31') // filter by date - 2022\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image\n\n// read the properties into a variable\nvar clbj2022_refl_properties = refl002_CLBJ_2022.toDictionary()\n\n// determine the release information for this BRDF-corrected image\nvar clbj2022_release_status = clbj2022_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Status:', clbj2022_release_status)\n\n// if you try to read in the release year, it will throw an error\n// since this data product is still PROVISIONAL, there is no release year\n// comment out these lines below to remove\nvar clbj2022_release_year = clbj2022_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Year:', clbj2022_release_year)\n\n// pull out the red, green, and blue bands\nvar refl002_CLBJ_2022_RGB = refl002_CLBJ_2022.select(['B053', 'B035', 'B019']);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl002_CLBJ_2022_RGB, refl_rgb_vis, 'CLBJ 2022 Bidirectional Reflectance RGB');\n</code></pre> <p></p> <p>Handling Errors</p> <p>If your code has any errors they will display in the Console tab in red. In this example, we tried to print out a property that does not exist because the data is Provisional, so there is no <code>RELEASE_YEAR</code>. You can comment out the lines of code starting with <code>var clbj2022_release_year</code> to prevent the error from displaying. If your code is not running as expected, errors displayed in the Console can be helpful for troubleshooting, as it will tell you how and where your code failed. Print statements throughout the code can also be helpful.</p> <p>Note that bidirectional reflectance data will remain provisional in 2025, since it is a new data product (as of 2024), and is planned to be incorporated into RELEASE-2026.</p> <p>You can toggle between the two layers by selecting the \"Layers\" tab in the upper right corner of the Map window. Check and uncheck the two layers (2021 and 2022) to see the differences. You can also use the slider to the right of the layer name to make one layer partially transparent. What observations can you make about these two datasets?</p> <p></p> <p>The BRDF and topographic corrections typically visibly improve striping (or BRDF effects) between adjacent flightlines, as we can see with these datasets at CLBJ, where the 2022 bidirectional reflectance (left) looks much more seamless than the 2021 directional reflectance data (right), which has some visible vertical artifacts. For most NEON sites, the flight lines are oriented N-S so the stripes in the directional reflectance data will be vertical, but there are a few sites with slightly different flight plans.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#summary","title":"Summary","text":"<p>You did it! You now have a basic understanding of the GEE Code Editor and its different components. You have also learned how to read a NEON AOP <code>ImageCollection</code> into a variable, import the variable into your session, and navigate through the ImageCollection Asset details to display information about the collection. You learned to read in an individual reflectance image, explore the image properties, and display a map of a true color image (RGB composite). And finally, you explored some of the differences between the directional and bidirectional (BRDF- and topographic corrected) reflectance data products at the site CLBJ.</p> <p>It doesn't seem like we've done much so far, but this is a already great achievement! With just a few lines of code, you can import an entire AOP hyperspectral dataset, which in most other coding environments, is more involved. One of the major challenges to working with AOP reflectance data is its large data volume, which typically requires high-performance computing environments to read in the data, visualize, and analyze it. There are also limited open-source tools for working with hyperspectral data; many of the established software suites require proprietary (and often expensive) licenses. In this lesson, with minimal code, we have loaded spectral, lidar, and camera data covering an entire AOP site, and are ready to start exploring and analyzing the data in a free geospatial cloud-computing platform.</p>"},{"location":"tutorials/01_intro_to_neon_aop_gee_datasets/#get-lesson-code","title":"Get Lesson Code","text":"<p>Intro to AOP GEE Image Collections</p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/","title":"Reflectance Pre-processing: Masking Out Bad Weather Data in GEE","text":"\ud83d\udccb Tutorial Details\ud83c\udff7\ufe0f Topics &amp; Data <ul> <li>Duration: 30 minutes</li> <li>Level: Intermediate</li> <li>Authors: Bridget M. Hass, John Musinsky</li> <li>Contributors: Tristan Goulden</li> </ul> <ul> <li>Topics: hyperspectral, remote-sensing</li> <li>Data Product: DP3.30006.001</li> </ul>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#introduction","title":"Introduction","text":"<p>Since reflectance data is generated from a passive energy source (the sun), data collected in cloudy sky conditions are not directly comparable to data collected in clear-sky conditions, as overhead clouds can obscure the incoming light source. AOP aims to collect data only in optimal (&lt;10% cloud-cover) weather conditions, but cannot always do so due to logistical constraints. The flight operators record the weather conditions during each flight, and this information is passed through to the final data product at the level of the flight line (as cloud conditions can change throughout the day).</p> <p>Cloud conditions are reported as: - Green (&lt;10% cloud cover) - Yellow (10-50% cloud cover) - Red (&gt;50% cloud cover)</p> <p>The figure below shows some examples of what the cloud conditions look like at different flights collected in the three different weather classes.</p> <p> Cloud cover percentage during AOP flights. Left: green (&lt;10%), Middle: yellow (10-50%), Right: red (&gt;50%).</p> <p>Airborne vs. Satellite Data</p> <p>There is an important distinction between airborne and satellite reflectance data. Satellite data is collected in all weather conditions, and the clouds are below the sensor, so algorithms can be generated to filter out cloudy pixels. With aerial data, we have more control over when the data are collected, to a degree. However, clouds may be present overhead, if it were deemed necessary to collect in sub-optimal weather conditions. AOP typically will only collect in \"red\" sky conditions if we are running out of time in a Domain and the weather isn't forecasted to improve.</p> <p>Since the clouds won't appear in the actual data, maintaining this record of cloud conditions is essential for properly understanding the data, and using it for change detection or other research applications. For a more direct comparison of reflectance values, we recommend only working with the clear-weather data. This lesson outlines how to do this in GEE.</p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to:</p> <ul> <li>Extract and plot the weather quality indicator band from the Surface Directional Reflectance dataset</li> <li>Mask reflectance data to pull out only clear-weather data for a given site</li> <li>Explore other QA bands included in the Reflectance data set</li> </ul>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#requirements","title":"Requirements","text":"<ul> <li>Complete the following introductory AOP GEE tutorials:<ul> <li>Introduction to AOP Public Datasets in Google Earth Engine (GEE)</li> </ul> </li> <li>An understanding of hyperspectral data and AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with:<ul> <li>Intro to Working with Hyperspectral Remote Sensing Data in R. You do not need to follow along with the code in those lessons, but at least read through to gain a better understanding of NEON's hyperspectral data product.</li> </ul> </li> </ul>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#read-in-the-aop-surface-directional-reflectance-2019-dataset-at-soap","title":"Read in the AOP Surface Directional Reflectance 2019 Dataset at SOAP","text":"<p>For this exercise, we will read in directional reflectance data from the NEON site Soaproot Saddle (SOAP) collected in 2019:</p> <pre><code>// Filter image collection by date and site to pull out a single image\nvar soapSDR = ee.ImageCollection(\"projects/neon-prod-earthengine/assets/HSI_REFL/001\")\n  .filterDate('2019-01-01', '2019-12-31')\n  .filterMetadata('NEON_SITE', 'equals', 'SOAP')\n  .first();\n</code></pre>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#display-the-qa-bands","title":"Display the QA Bands","text":"<p>From the previous lesson, recall that the reflectance images include 442 bands. Bands 0-425 are the data bands, which store the spectral reflectance values for each wavelength recorded by the NEON Imaging Spectrometer (NIS). The remaining bands (426-441) contain metadata and QA information that are important for understanding and properly interpreting the hyperspectral data. The data bands all follow the naming convention B001, B002, ..., B426, and the QA bands have more descriptive names that start with something other than the letter \"B\", so we can use that information to extract the QA bands.</p> <pre><code>// Pull out and display only the qa bands (these all start with something other than B)\n// '[^B].*' is a regular expression to pull out bands that don't start with B\nvar soapSDR_qa = soapSDR.select('[^B].*')\nprint('QA Bands',soapSDR_qa)\n</code></pre> <p></p> <p>Most of these QA bands are inputs to and outputs from the Atmospheric Correction (ATCOR), the process which converts radiance to atmospherically corrected reflectance. We will elaborate on these QA bands further, and encourage you to read more details about these data in the NEON Imaging Spectrometer Radiance to Reflectance Algorithm Theoretical Basis Document. For the purposes of this exercise, we will focus on the Weather Quality Indicator band.</p> <p>Exploring Other QA Bands</p> <p>Note that you can explore each of the QA bands, following similar steps below, adjusting the band names and values accordingly.</p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#read-in-the-weather-quality-indicator-band","title":"Read in the Weather Quality Indicator Band","text":"<p>The weather information, called <code>Weather_Quality_Indicator</code> is one of the most important pieces of QA information that is collected about the NIS data, as it has a direct impact on the reflectance values.</p> <p>These next lines of code pull out the <code>Weather_Quality_Indicator</code> band, select the \"green\" weather data from that band, and apply a mask to keep only the clear-weather data, which is saved to the variable <code>soapSDR_clear</code>.</p> <pre><code>// Extract a single band Weather Quality QA layer\nvar soapWeather = soapSDR.select(['Weather_Quality_Indicator']);\n\n// Select only the clear weather data (&lt;10% cloud cover)\nvar soapClearWeather = soapWeather.eq(1); // 1 = 0-10% cloud cover\n\n// Mask out all cloudy pixels from the SDR image\nvar soapSDR_clear = soapSDR.updateMask(soapClearWeather);\n</code></pre>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#plot-the-weather-quality-band-data","title":"Plot the Weather Quality Band Data","text":"<p>For reference, we can plot the weather band data, using AOP's stop-light (red/yellow/green) color scheme, with the code below:</p> <pre><code>// center the map at the lat / lon of the site, set zoom to 12\nMap.setCenter(-119.25, 37.06, 11);\n\n// Define a palette for the weather - to match NEON AOP's weather color conventions\nvar gyrPalette = [\n  '00ff00', // green (&lt;10% cloud cover)\n  'ffff00', // yellow (10-50% cloud cover)\n  'ff0000' // red (&gt;50% cloud cover)\n];\n\n// Display the weather band (cloud conditions) with the green-yellow-red palette\nMap.addLayer(soapWeather,\n             {min: 1, max: 3, palette: gyrPalette, opacity: 0.3},\n             'SOAP 2019 Cloud Cover Map');\n</code></pre>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#plot-the-clear-weather-reflectance-data","title":"Plot the Clear-Weather Reflectance Data","text":"<p>Finally, we can plot a true-color image of only the clear-weather data, from <code>soapSDR_clear</code> that we created earlier:</p> <pre><code>// Create a 3-band cloud-free image\nvar soapSDR_RGB = soapSDR_clear.select(['B053', 'B035', 'B019']);\n\n// Display the SDR image\nMap.addLayer(soapSDR_RGB, {min:103, max:1160}, 'SOAP 2019 Reflectance RGB');\n</code></pre> <p></p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#plot-acquisition-dates","title":"Plot Acquisition Dates","text":"<p>We can apply the same concepts to explore another one of the QA bands, this time let's look at the <code>Acquisition_Date</code>. This may be useful if you are trying to find the dates that correspond to field data you've collected, or you want to scale up to satellite data, for example. To determine the minimum and maximum dates, you can use <code>reduceRegion</code> with the reducer <code>ee.Reducer.minMax()</code> as follows. Then use these start and end date values in the visualization parameters.</p> <p>Managing Layer Display</p> <p>You may not wish to show every layer by default if you are plotting many layers. You can choose not to display a layer by default by including a \"0\" as the last input of <code>Map.addLayer</code>. Once you run the code, to toggle the layer on, find the Layers tab in the upper right corner of the Map Window and check the box to the left of the layer you want to display. You can click on the lock icon to make it so that the Layers full display stays open (by default it minimizes).</p> <pre><code>// Extract acquisition dates QA band\nvar soapDates = soapSDR.select(['Acquisition_Date']);\n\n// Get the minimum and maximum values of the soapDates band\nvar minMaxValues = soapDates.reduceRegion({reducer: ee.Reducer.minMax(),maxPixels: 1e10})\nprint('min and max dates', minMaxValues);\n\n// Map acquisition dates, don't display layer by default\nMap.addLayer(soapDates,\n            {min:20190612, max:20190616, opacity: 0.5},\n            'SOAP 2019 Acquisition Dates',0);\n</code></pre> <p></p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#other-qa-considerations","title":"Other QA Considerations","text":"<p>This lesson is intended to give you a quick introduction to some of the QA factors to consider when working with NEON AOP data, and is not meant to be comprehensive. When working with hyperspectral data, there are also invalid and noisy bands that you will likely want to remove before working with the full spectra (these bad bands are not unique to NEON hyperspectral data; for example NASA AVIRIS and EMIT hyperspectral data have the same limitations).</p> <p>Additional Resources</p> <p>Please see the lesson Plot spectral signatures of AOP Reflectance data in GEE for more details on these \"bad bands\". The Algorithm Theoretical Basis Documents (ATBDs) for the directional and bidirectional reflectance datasets, linked from the NEON Data Product Pages (DP3.30006.001, DP3.30006.002) and from the Quick Start Guides linked in the descriptions in the NEON Publisher Datasets pages on GEE, provide more comprehensive details on how these data products were derived and additional QA factors to consider.</p> <p>When pairing NEON data with satellite data, you will also need to factor in differences in how the datasets were processed, such as the atmospheric correction algorithm used, and other corrections that may or may not be applied (e.g. BRDF and topographic corrections) to both/all datasets you are integrating. If you can't find the information you need in the documentation, please reach out to NEON scientists using the NEON Contact Us form with any questions.</p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#summary","title":"Summary","text":"<p>In this lesson you learned how to read in Weather Quality Information from the Reflectance QA bands in GEE. You learned to mask data to keep only the imagery collected in the clearest sky conditions (&lt;10% cloud cover), and plot the three weather quality classes. You also learned how to find the other QA bands. Following a similar approach, you can explore each of the QA bands similarly. Filtering by the weather quality is an important first pre-processing step to working with NEON hyperspectral data, and is essential for interpreting the data and carrying out subsequent data analysis.</p>"},{"location":"tutorials/02_neon_reflectance_weather_qa/#get-lesson-code","title":"Get Lesson Code","text":"<p>AOP GEE SDR Weather Quality</p>"},{"location":"tutorials/03_plot_spectral_signature/","title":"Plot Spectral Signatures of AOP Reflectance Data in GEE","text":"\ud83d\udccb Tutorial Details\ud83c\udff7\ufe0f Topics &amp; Data <ul> <li>Duration: 30 minutes</li> <li>Level: Intermediate</li> <li>Authors: Bridget Hass, John Musinsky</li> <li>Contributors: Tristan Goulden, Lukas Straube</li> </ul> <ul> <li>Topics: lidar, hyperspectral, camera, remote-sensing</li> <li>Data Products: DP3.30006.001, DP3.30006.002, DP3.30010.001, DP3.30015.001, DP3.30024.001</li> </ul>"},{"location":"tutorials/03_plot_spectral_signature/#objectives","title":"Objectives","text":"<p>After completing this activity, you will be able to:</p> <ul> <li>Read in and map a single AOP Hyperspectral reflectance image at a NEON site</li> <li>Link spectral band numbers to wavelength values</li> <li>Create an interactive plot to display the spectral signature of a given pixel upon clicking</li> </ul>"},{"location":"tutorials/03_plot_spectral_signature/#requirements","title":"Requirements","text":"<ul> <li>Complete the following introductory AOP GEE tutorials:<ul> <li>Introduction to AOP Public Datasets in Google Earth Engine (GEE)</li> </ul> </li> <li>An understanding of hyperspectral data and AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with the Intro to Working with Hyperspectral Remote Sensing Data tutorial. You do not need to follow along with the R code in those lessons, but at least read through to gain a better understanding NEON's spectral data products.</li> </ul>"},{"location":"tutorials/03_plot_spectral_signature/#read-in-the-aop-directional-reflectance-image","title":"Read in the AOP Directional Reflectance Image","text":"<p>As should be familiar by now from the previous tutorials in this series, we'll start by pulling in the AOP data. For this exercise we will only read directional reflectance data from SOAP collected in 2021:</p> <pre><code>// Filter image collection by date and site\nvar soapSDR = ee.ImageCollection(\"projects/neon-prod-earthengine/assets/HSI_REFL/001\")\n  .filterDate('2021-01-01', '2021-12-31')\n  .filterMetadata('NEON_SITE', 'equals', 'SOAP')\n  .first();\n\n// Create a 3-band true-color image\nvar soapSDR_RGB = soapSDR.select(['B053', 'B035', 'B019']);\n\n// Display the SDR image\nMap.addLayer(soapSDR_RGB, {min:103, max:1160}, 'SOAP 2021 Reflectance RGB');\n\n// Center the map around the soapSDR_RGB object, set zoom to 12\nMap.centerObject(soapSDR_RGB, 12);\n</code></pre>"},{"location":"tutorials/03_plot_spectral_signature/#extract-data-bands","title":"Extract Data Bands","text":"<p>Next we will extract only the \"data\" bands in order to plot the spectral information. The reflectance data contains 426 data bands, and a number of QA/Metadata bands that provide additional information that can be useful in interpreting and analyzing the data (such as the Weather Quality Information). For plotting the spectra, we only need the data bands.</p> <pre><code>// Pull out only the data bands (these all start with B, eg. B001)\nvar soapSDR_data = soapSDR.select('B.*')\nprint('SOAP SDR Data',soapSDR_data)\n\n// Read in the properties as a dictionary\nvar properties = soapSDR.toDictionary()\n</code></pre>"},{"location":"tutorials/03_plot_spectral_signature/#extract-wavelength-information-from-the-properties","title":"Extract Wavelength Information from the Properties","text":"<p>Similar to the code above, we can use a regular expression to pull out the wavelength information from the properties. The wavelength and Full Width Half Max (FWHM) information is stored in the properties starting with WL_FWHM_B. These are stored as strings, so the next step is to write a function that converts the string to a float, and only pulls out the center wavelength value (by splitting on the \",\" and pulling out only the first value). This is all we need for now, but if you needed the FWHM information, you could write a similar function. Lastly, we'll apply the function using GEE <code>.map</code> to pull out the wavelength information. We can then print some information about what we've extracted.</p> <pre><code>// Select the WL_FWHM_B*** band properties (using regex)\nvar wl_fwhm_dict = properties.select(['WL_FWHM_B+\\\\d{3}']);\n\n// Pull out the wavelength, fwhm values to a list\nvar wl_fwhm_list = wl_fwhm_dict.values()\nprint('Wavelength FWHM list:',wl_fwhm_list)\n\n// Function to pull out the wavelength values only and convert the string to float\nvar get_wavelengths = function(x) {\n  var str_split = ee.String(x).split(',')\n  var first_elem = ee.Number.parse((str_split.get(0)))\n  return first_elem\n}\n\n// apply the function to the wavelength full-width-half-max list\nvar wavelengths = wl_fwhm_list.map(get_wavelengths)\n\nprint('Wavelengths:',wavelengths)\nprint('# of data bands:',wavelengths.length())\n</code></pre>"},{"location":"tutorials/03_plot_spectral_signature/#interactively-plot-the-spectral-signature-of-a-pixel","title":"Interactively Plot the Spectral Signature of a Pixel","text":"<p>Lastly, we'll create a plot in the Map panel, and use the <code>Map.onClick</code> function to create a spectral signature of a given pixel that you click on. Most of the code below specifies formatting, figure labels, etc.</p> <pre><code>// Create a panel to hold the spectral signature plot\nvar panel = ui.Panel();\npanel.style().set({width: '600px',height: '300px',position: 'top-left'});\nMap.add(panel);\nMap.style().set('cursor', 'crosshair');\n\n// Create a function to draw a chart when a user clicks on the map.\nMap.onClick(function(coords) {\n  panel.clear();\n  var point = ee.Geometry.Point(coords.lon, coords.lat);\n    wavelengths.evaluate(function(wvlnghts) {\n      var chart = ui.Chart.image.regions({\n        image: soapSDR_data,\n        regions: point,\n        scale: 1,\n        seriesProperty: '\u03bb (nm)',\n        xLabels: wavelengths.getInfo()\n    });\n    chart.setOptions({\n      title: 'Reflectance',\n      hAxis: {title: 'Wavelength (nm)',\n      vAxis: {title: 'Reflectance'},\n      gridlines: { count: 5 }}\n    });\n    // Create and update the location label\n    var location = 'Longitude: ' + coords.lon.toFixed(2) + ' ' +\n                   'Latitude: ' + coords.lat.toFixed(2);\n    panel.widgets().set(1, ui.Label(location));\n    panel.add(chart);\n  })\n});\n</code></pre> <p>When you run this code (linked at the bottom), you will see the SOAP 2021 directional reflectance layer show up in the Map panel, along with an empty white figure panel in the lower left corner. When you click anywhere in the reflectance image, the empty figure panel will be populated with the spectral signature of the pixel you clicked on.</p> <p></p>"},{"location":"tutorials/03_plot_spectral_signature/#qa-considerations-bad-and-noisy-bands","title":"QA Considerations - Bad and Noisy Bands","text":"<p>Let's zoom in on the spectral signature figure to take a closer look. Specifically, you can easily spot some QA considerations that are important to factor in if you intend to work with all 426 bands of data.</p> <p></p>"},{"location":"tutorials/03_plot_spectral_signature/#water-vapor-band-windows","title":"Water Vapor Band Windows","text":"<p>We can see from the spectral profile above that the reflectance values dip to below zero around ~1400 nm and ~1800 nm. These are water vapor band windows, resulting from water vapor which absorbs light between wavelengths 1340-1445 nm and 1790-1955 nm. The atmospheric correction that converts radiance to reflectance subsequently results in a spike at these two bands, and are invalid values. They are set to -100 for the reflectance data in GEE.</p> <p>Water Vapor Bands in Different Datasets</p> <p>For more details on these bands, please refer to the Plot a Spectral Signature from Reflectance Data in Python tutorial. If you are working with hyperspectral data downloaded from the NEON Data Portal, these water vapor band windows are not set to -100, so this is one difference between the reflectance datasets on GEE and the datasets and the original hdf5 reflectance datasets.</p>"},{"location":"tutorials/03_plot_spectral_signature/#noisy-bands","title":"Noisy Bands","text":"<p>You may also notice that the reflectance values at the beginning (~380 nm) and end (~2500 nm) of the wavelength range spike up, relative to the other nearby bands. These are not a feature of the actual data. The first and last bands are more prone to have noisy values due to imperfect calibration of the sensor at the lowest and highest reflectance bands.</p> <p>Best Practice for Band Selection</p> <p>Best practice is to leave out the first and last 5-10 bands of data; you can inspect a spectral signature plot to determine how many bands to remove.</p>"},{"location":"tutorials/03_plot_spectral_signature/#summary","title":"Summary","text":"<p>In this lesson you learned how to read in wavelength information from the Surface Directional Reflectance properties in GEE, created functions to convert from one data format to another, and created an interactive plot to visualize the spectral signature of a selected pixel. You can quickly see how GEE is a powerful tool for interactive data visualization and exploratory analysis.</p>"},{"location":"tutorials/03_plot_spectral_signature/#get-lesson-code","title":"Get Lesson Code","text":"<p>AOP GEE Reflectance Plot Spectra</p>"}]}